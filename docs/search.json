[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nC√≥digo\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "",
    "text": "Esta p√°gina web forma parte del curso ‚ÄúAn√°lisis de textos literarios con R‚Äù. En ella, se recogen los materiales y ejemplos que se desarrollar√°n durante las sesiones.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#el-curso",
    "href": "index.html#el-curso",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "",
    "text": "Esta p√°gina web forma parte del curso ‚ÄúAn√°lisis de textos literarios con R‚Äù. En ella, se recogen los materiales y ejemplos que se desarrollar√°n durante las sesiones.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#los-profesores",
    "href": "index.html#los-profesores",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "Los profesores",
    "text": "Los profesores\n\n\n\n\n\n\nRodrigo Rodrigues-Silveira\nrodrodr@usal.es\nProfesor de ciencia pol√≠tica de la USAL. Director del proyecto ‚ÄúComportamiento legislativo y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento). Miembro de los GIR ‚ÄúPol√≠tica Comparada en Am√©rica Latina‚Äù y ‚ÄúTecnolog√≠a y poder en el pensamiento y las letras‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\nSheila Pastor\nsheilap@usal.es\nProfesora en el Departamento de Literatura espa√±ola e hispanoamericana de la USAL. Miembro del Instituto de Estudios Medievales y Renacentistas y de Humanidades Digitales y del GIR Tecnolog√≠a y poder en el pensamiento y las letras.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#el-contenido",
    "href": "index.html#el-contenido",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "El contenido",
    "text": "El contenido\nDurante el curso se abordar√°n los siguientes temas:\n\npreparaci√≥n de textos literarios para an√°lisis cuantitativos\nan√°lisis de frecuencias de palabras\ncodificaci√≥n tem√°tica\nan√°lisis de conglomerados clusters\nescalonado de textos (uni y multidimensional)\nmodelado de t√≥picos\nan√°lisis de redes sociales\nt√©cnicas de visualizaci√≥n de texto",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#sesiones",
    "href": "index.html#sesiones",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "Sesiones",
    "text": "Sesiones\nLas sesiones tendr√°n lugar en el et√©reo espacio de la nube, en la plataforma Zoom. Los enlaces de acceso a las sesiones se enviar√°n a los correos electr√≥nicos de los participantes.\nD√çA 1 - 16/06/2025 de 10 a 14h\nD√çA 2 - 23/06/2025 de 10 a 14h",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "index.html#servicio-t√©cnico",
    "href": "index.html#servicio-t√©cnico",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "ü§ñ Servicio t√©cnico ü§ñ",
    "text": "ü§ñ Servicio t√©cnico ü§ñ\nPara que pod√°is reproducir los ejemplos de an√°lisis presentados durante el curso deb√©is instalar en vuestros ordenadores el R y el RStudio Desktop.\nTambi√©n deb√©is ejecutar el siguiente c√≥digo en R que instala los paquetes necesarios.\nAVISO IMPORTANTE PARA INICIANTES EN R\nPara que funcione el c√≥digo abajo:\n\ndebes ejecutar cada l√≠nea de una en una y esperar que finalice antes de ejecutar la siguiente. Primero la que empieza con pc, luego, install.packages(pc) y, finalmente, una vez terminado el paso anterior: devtools::install_github(‚Äúrodrodr/tenet‚Äù, force=T).\nPuede que aparezcan algunos mensajes. El primero es si quieres reiniciar R, le das a ‚ÄúNo‚Äù. El segundo es si deseas actualizar los paquetes y debes decir: ‚Äú1 - All‚Äù. Finalmente, si te pide instalar paquetes ‚Äúfrom source‚Äù (en Mac puede aparecer), elegid, ‚Äún‚Äù (no).\n\nCon eso, tendr√©is para instalar los paquetes necesarios para el curso.\n\n\nC√≥digo\n# Crea un vector con los paquetes a instalar\npc &lt;- c(\"quanteda\",\"quanteda.textplots\",\"pdftools\",\n        \"quanteda.textmodels\",\"quanteda.textstats\",\n        \"stringi\",\"readr\",\"gutenbergr\",\"ggplot2\",\n        \"ggrepel\",\"reactable\",\"tidyverse\",\"devtools\",\n        \"egg\",\"network\",\"sna\",\"ggnetwork\",\"poliscidata\",\n        \"udpipe\",\"dplyr\",\"syuzhet\",\"ggiraph\",\"networkD3\",\n        \"igraph\",\"topicmodels\")\n\n# Instala los paquetes\ninstall.packages(pc)\n\n# Instala el paquete tenet que no est√° en CRAN\ndevtools::install_github(\"rodrodr/tenet\", force=T)",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  },
  {
    "objectID": "prepa.html",
    "href": "prepa.html",
    "title": "Preparaci√≥nPreparaci√≥n de los textos en R",
    "section": "",
    "text": "El R permite diferentes tipos de an√°lisis de datos aplicados a textos. Seg√∫n las caracter√≠sticas de cada obra, podemos llevar a cabo un an√°lisis de frecuencia de palabras, de sentimientos, emplear diccionarios (l√©xicos o glosarios) para identificar ciertos rasgos o atributos. Tambi√©n resulta posible jugar con su estructura, agregando los datos por p√°rrafo, cap√≠tulo, personaje o cualquier otra caracter√≠sticas que lo permita.\nPara el presente curso, hemos seleccionado dos textos literarios: una novela y una obra de teatro. La novela es ‚ÄúLa Regenta‚Äù, de Leopoldo Alas ‚ÄúClar√≠n‚Äù y la pieza de teatro ‚ÄúTres sombreros de copa‚Äù, de Miguel Mihura. Ambas obras son cl√°sicos de la literatura espa√±ola y permiten comparar los resultados de los an√°lisis de textos literarios. Adem√°s de por su alto valor literario, nos interesan en particular por sus diferencias estructurales y c√≥mo nos permiten realizar distintos tipos de an√°lisis.\nAunque ambas puedan ser objeto de la mayor parte de los an√°lisis que introduciremos aqu√≠, cada una de ellas nos permitir√° aplicar distintas t√©cnicas de modo m√°s fruct√≠fero. Por ejemplo, en ‚ÄúLa Regenta‚Äù nos interesar√° explorar la estructura de los cap√≠tulos, los temas que aparecen, sus principales personajes, la frecuencia de palabras y la red de palabras. En el caso de ‚ÄúTres sombreros de copa‚Äù, nos interesar√° explorar la red de di√°logos y medir las diferentes formas de centralidad o influencia de los personajes en la trama.",
    "crumbs": [
      "Preparaci√≥n"
    ]
  },
  {
    "objectID": "prepa.html#introducci√≥n",
    "href": "prepa.html#introducci√≥n",
    "title": "Preparaci√≥nPreparaci√≥n de los textos en R",
    "section": "",
    "text": "El R permite diferentes tipos de an√°lisis de datos aplicados a textos. Seg√∫n las caracter√≠sticas de cada obra, podemos llevar a cabo un an√°lisis de frecuencia de palabras, de sentimientos, emplear diccionarios (l√©xicos o glosarios) para identificar ciertos rasgos o atributos. Tambi√©n resulta posible jugar con su estructura, agregando los datos por p√°rrafo, cap√≠tulo, personaje o cualquier otra caracter√≠sticas que lo permita.\nPara el presente curso, hemos seleccionado dos textos literarios: una novela y una obra de teatro. La novela es ‚ÄúLa Regenta‚Äù, de Leopoldo Alas ‚ÄúClar√≠n‚Äù y la pieza de teatro ‚ÄúTres sombreros de copa‚Äù, de Miguel Mihura. Ambas obras son cl√°sicos de la literatura espa√±ola y permiten comparar los resultados de los an√°lisis de textos literarios. Adem√°s de por su alto valor literario, nos interesan en particular por sus diferencias estructurales y c√≥mo nos permiten realizar distintos tipos de an√°lisis.\nAunque ambas puedan ser objeto de la mayor parte de los an√°lisis que introduciremos aqu√≠, cada una de ellas nos permitir√° aplicar distintas t√©cnicas de modo m√°s fruct√≠fero. Por ejemplo, en ‚ÄúLa Regenta‚Äù nos interesar√° explorar la estructura de los cap√≠tulos, los temas que aparecen, sus principales personajes, la frecuencia de palabras y la red de palabras. En el caso de ‚ÄúTres sombreros de copa‚Äù, nos interesar√° explorar la red de di√°logos y medir las diferentes formas de centralidad o influencia de los personajes en la trama.",
    "crumbs": [
      "Preparaci√≥n"
    ]
  },
  {
    "objectID": "prepa.html#la-regenta-p√°rrafos-y-cap√≠tulos",
    "href": "prepa.html#la-regenta-p√°rrafos-y-cap√≠tulos",
    "title": "Preparaci√≥nPreparaci√≥n de los textos en R",
    "section": "‚ÄúLa Regenta‚Äù: p√°rrafos y cap√≠tulos",
    "text": "‚ÄúLa Regenta‚Äù: p√°rrafos y cap√≠tulos\n\nEstructura de la base de datos\nLa novela ‚ÄúLa Regenta‚Äù es una obra de Leopoldo Alas ‚ÄúClar√≠n‚Äù publicada en 1884. Como sab√©is, se trata de una de las novelas m√°s importantes de la literatura espa√±ola y representa uno de los mejores ejemplares de la novela realista/naturalista del siglo XIX. Se conforma por 30 cap√≠tulos, divididos en dos tomos de 15 apartados cada uno.\nEl objetivo de esta presente secci√≥n consiste en preparar el texto de ‚ÄúLa Regenta‚Äù para su an√°lisis por medio de herramientas y t√©cnicas estad√≠sticas. De modo concreto, nos interesa organizar el texto en dos bases de datos. La primera organizada por p√°rrafos y la segunda por cap√≠tulos. Cada una de ellas permitir√° la aplicaci√≥n de an√°lisis con distinto nivel de detalle.\nLlamaremos aqu√≠ ‚Äúbase de datos‚Äù una tabla de datos con N filas y N columnas. Cada fila corresponder√° a un p√°rrafo o cap√≠tulo y cada columna a una variable que nos interese analizar. Tendremos, por lo tanto, dos unidades de agregaci√≥n y sus correspondientes atributos: parte (t√≠tulo, pr√≥logo o tomo), cap√≠tulo, p√°rrafo (en su caso) y texto.\n\n\nM√©todo de conversi√≥n de texto a datos\nResulta muy sencillo descargar la novela ‚ÄúLa Regenta‚Äù. Podemos emplear el paquete gutenbergr para descargar el texto directamente en R y trabajar con √©l. Solo tenemos que a√±adir un paso m√°s al trabajo: convertir la codificaci√≥n de caracteres a ‚Äúlatin1‚Äù para evitar problemas con las tildes.\n\n\nC√≥digo\n# Abre la librer√≠a gutenbergr\n# para bajar el texto\nlibrary(gutenbergr)\n\n# Baja el texto de \"La Regenta\"\n# cuyo id es igual 17073\nre &lt;- gutenberg_download(gutenberg_id = 17073, \n                         verbose = FALSE)\n\n# Cambia la codificaci√≥n de caracteres a\n# a latin1 para evitar problemas con las tildes\nEncoding(re$text) &lt;- \"latin1\"\n\n# Convierte el texto en un solo string\nre &lt;- paste0(re$text, \n             collapse = \"\\n\")\n\n\nCon ese sencillo primer paso, ya tenemos la novela en nuestro ordenador. No obstante, hacen falta algunos tratamientos adicionales para convertir el texto en una base de datos que se pueda emplear en comparaciones, an√°lisis de redes de palabras, etc.\nLa etapa siguiente trata de eliminar los saltos de l√≠nea y recuperar la estructura de los p√°rrafos. Para ello, empleamos una expresi√≥n regular que nos permita identificar los p√°rrafos y corregir los saltos de l√≠nea al final de cada frase.\n\n\nC√≥digo\n# Carga el paquete stringi\n# que permite trabajar con expresiones regulares\n# y otras tareas de manipulaci√≥n\n# de textos\nlibrary(stringi)\n\n# Corrige los p√°rrafos para que no tengan\n# un salto de l√≠nea al final de cada frase\nrx &lt;- stri_replace_all_regex(\n            re,\n            \"(\\\\S|\\\\p{L})(\\n)(\\\\S{1}|\\\\p{L})\",\"$1 $3\")\n\n\nPara entender lo que hemos hecho, explicaremos la gram√°tica de la expresi√≥n regular empleada:\n\n(\\\\S|\\\\p{L}): busca uno o m√°s caracteres que no sean espacios en blanco (\\S) o (|) una letra con acentuaci√≥n latina (\\p{L}).\n(\\n): busca un salto de l√≠nea.\n(\\\\S{1}|\\\\p{L}): busca un √∫nico car√°cter que no sea un espacio en blanco (\\S{1}) o (|) una letra con acentuaci√≥n latina (\\p{L}).\n\ny los reemplaza por:\n\n$1 $3: por el primer car√°cter encontrado ($1), un espacio y el √∫ltimo car√°cter encontrado ($3).\n\nDe ese modo:\n‚ÄúEl poeta es un fingidor.‚Äù\n‚ÄúFinge tan completamente‚Äù\n‚Äúque llega a fingir que es dolor‚Äù\n‚Äúel dolor que de verdad siente.‚Äù\nse convierte en:\n‚ÄúEl poeta es un fingidor. Finge tan completamente que llega a fingir que es dolor el dolor que de verdad siente.‚Äù\nDe ese modo, el R lo hace para TODOS los p√°rrafos a la vez y nos ahora mucho trabajo de preparaci√≥n de cualquier texto.\nUna vez corregidos los p√°rrafos, podemos convertir el texto en un vector de l√≠neas para poder trabajar con √©l.\n\n\nC√≥digo\n# Carga el paquete readr, que permite\n# convertir textos en vectores\nlibrary(readr)\n\n# Vuelve a seleccionar los p√°rrafos\nre &lt;- read_lines(rx)\n\n\nEl resultado es un vector de caracteres llamado re con 12.164 elementos. Cada elemento corresponde o bien a un p√°rrafo o bien a un salto de l√≠nea indicando la separaci√≥n entre dos p√°rrafos.\nCon esa informaci√≥n, nos interesa asociar cada p√°rrafo a la estructura formal de la novela. En el caso de ‚ÄúLa Regenta‚Äù, la novela est√° dividida en un pr√≥logo, dos tomos y 30 cap√≠tulos, siendo los quince primeros pertenecientes al primer tomo y los quince restantes al segundo.\nPara llevar a cabo dicha tarea, debemos identificar los elementos que marcan el inicio de cada parte de la novela. En este caso, el pr√≥logo, los tomos y los cap√≠tulos. El pr√≥logo y los tomos son f√°cilmente identificables por su t√≠tulo. Basta con buscar en qu√© l√≠neas aparecen las palabras ‚ÄúPr√≥logo‚Äù y ‚ÄúTomo‚Äù para identificarlos.\nLos cap√≠tulos, por otra parte, exigen un poco m√°s de trabajo. Se enumeran con n√∫meros romanos precedidos y seguidos de dos guiones. Por ejemplo, ‚Äú‚ÄìI‚Äì‚Äù indica el punto en el que empieza primer cap√≠tulo. ‚Äú‚ÄìII‚Äì‚Äù encuentra el elemento que da inicio al segundo y as√≠ sucesivamente. En nuestro ejemplo, el primer cap√≠tulo empieza en la l√≠nea 59 y el segundo en la 311. Por lo tanto, sabemos que todos los p√°rrafos comprendidos entre 59 y 310 corresponden al primer cap√≠tulo. Con esa informaci√≥n en mano, lo que tenemos que hacer es asociar a cada p√°rrafo su correspondiente t√≠tulo, tomo o cap√≠tulo.\nEl primer procedimiento consiste en encontrar los √≠ndices de las partes y cap√≠tulos de la novela y sus descripciones:\n\n\nC√≥digo\n# Encuentra los √≠ndices del pr√≥logo, de\n# los tomos y los cap√≠tulos\npro &lt;- grep(\"Pr√≥logo\",re) # pr√≥logo\ntm &lt;- c(grep(\"Tomo\",re), \n        grep(\"TOMO\",re)) # tomos - √≠ndice\ncap &lt;- which(stri_detect_regex(re, \n                            \"^(--)([A-Z]+)(--)$\")==TRUE) # cap√≠tulos\n\n# Crea vectores que obtienen\n# los t√≠tulos de los tomos y los cap√≠tulos\ntx &lt;- re[tm] # tomos - textos\ncx &lt;- re[cap] # cap√≠tulos - textos\n\n\nCon los √≠ndices, puedo repetir cada nombre de tomo, cap√≠tulo, pr√≥logo, etc. en funci√≥n de cu√°ntos p√°rrafos tenga cada uno. De ese modo, puedo asociar cada p√°rrafo a su correspondiente t√≠tulo, tomo o cap√≠tulo:\n\n\nC√≥digo\n# Genera un vector que identifica qu√© l√≠neas\n# pertenecen al t√≠tulo. En la estructura de\n# la novela el pr√≥logo se sigue al t√≠tulo,\n# por eso decimos que se repita la palabra\n# \"T√≠tulo\" del primer p√°rrafo hasta el\n# inmediatamente anterior al pr√≥logo (pro-1).\nti &lt;- rep(\"T√≠tulo\", \n          length(1:(pro-1)))\n\n# Hacemos algo parecido con el pr√≥logo. \n# Puesto que antecede al primer tomo,\n# repetimos \"Pr√≥logo\" desde la primera \n# vez que aparece (pro) hasta el p√°rrafo\n# anterior al primer tomo (tm[1]-1).\npro &lt;- rep(\"Pr√≥logo\", \n           length(pro:(tm[1]-1)))\n\n# Para los tomos\n\n# Encuentra el tama√±o en p√°rrafos\n# de cada tomo\nlen &lt;- diff(c(tm, length(re)+1))\n\n# Repite la descripci√≥n o el nombre\n# de cada tomo para identificar\n# cada p√°rrafo\nta &lt;- sapply(\n        1:(length(tx)), \n          function(i){\n            rep(tx[i], len[i])\n          }, \n      simplify = TRUE)\n\nta &lt;- unlist(ta)\n\n# Para los cap√≠tulos\n\n# Encuentra el tama√±o en p√°rrafos\n# de cada cap√≠tulo\nlen &lt;- diff(c(cap, length(re)+1))\n\n# Repite la descripci√≥n o el nombre\n# de cada cap√≠tulo para identificar\n# cada p√°rrafo\nca &lt;- sapply(\n  1:(length(cx)), \n  function(i){\n    rep(cx[i], len[i])\n  }, \n  simplify = TRUE)\n\nca &lt;- unlist(ca)\n\n\nFinalmente, empleo todos los vectores generados para crear una base de datos que refleje de modo correcto la parte, el cap√≠tulo y el texto de cada p√°rrafo:\n\n\nC√≥digo\n# Crea un data frame con los textos, la \n# identificaci√≥n, de la parte y del cap√≠tulo\n\n# Combina los vectores de t√≠tulo,\n# pr√≥logo, tomos en un vetor pt (parte)\npt &lt;- c(ti,pro,ta)\n\n# A√±ade \"Previa\" para identificar \n# aquellos p√°rrafos que pertenecen \n# al t√≠tulo, pr√≥logo y presentaci√≥n \n# del primer tomo y combina con los \n# cap√≠tulos\ncp &lt;- c(rep(\"Previa\", 58),\n        ca)\n\n# Genera una base de datos con las\n# informaciones completas de\n# identificaci√≥n de las partes,\n# cap√≠tulos y el texto.\ndx &lt;- data.frame(parte = pt, \n                 capitulo= cp, \n                 texto = re)\n\n\nAhora, nos toca transformar la numeraci√≥n de los cap√≠tulos para poder mantener un orden secuencial. Adem√°s, nos interesa saber el n√∫mero del p√°rrafo en cada cap√≠tulo, para poder mencionar exactamente d√≥nde se encuentra una referencia exacta en el texto. Tambi√©n queremos eliminar la informaci√≥n que no nos interesa, como los espacios en blanco entre p√°rrafos:\n\n\nC√≥digo\n# Elimina los guiones de al identificaci√≥n\n# de cada cap√≠tulo\ndx$capitulo &lt;- gsub(\"--\",\"\",dx$capitulo)\n\n# Convierte los textos de identificaci√≥n\n# de los cap√≠tulos en n√∫meros romanos\n# y luego los convierte en num√©rico\ndx$roman &lt;- as.roman(dx$capitulo)\ndx$roman &lt;- as.numeric(dx$roman)\n\n# Asigna los valores num√©ricos a los cap√≠tulos\ndx$capitulo[! is.na(dx$roman)] &lt;- dx$roman[! is.na(dx$roman)]\ndx$capitulo[is.na(dx$roman)] &lt;- dx$parte[ is.na(dx$roman)]\n\n# A√±ade un 0 (cero) para los cap√≠tulos menores\n# a 10.\ndx$capitulo[nchar(dx$capitulo)==1] &lt;- paste0(\"0\",dx$capitulo[nchar(dx$capitulo)==1])\n\n# A√±ade 001 y 002 para el t√≠tulo y el pr√≥logo.\n# De ese modo, quedan los primeros una vez se\n# ordene la base de datos.\ndx$capitulo[dx$capitulo==\"T√≠tulo\"] &lt;- \"001 - T√≠tulo\"\ndx$capitulo[dx$capitulo==\"Pr√≥logo\"] &lt;- \"002 - Pr√≥logo\"\n\n# Elimina la informaci√≥n que no interesa\ndx &lt;- dx[dx$parte!=dx$texto,]\ndx$roman &lt;- NULL\ndx &lt;- dx[dx$texto!=\"\",]\n\n# A√±ade un n√∫mero de p√°rrafo a cada p√°rrafo \n# de cada cap√≠tulo. As√≠ que siempre se reinicia\n# en cuenteo a cada nuevo cap√≠tulo.\nlibrary(dplyr)\ndx &lt;- dx |&gt; \n  group_by(capitulo) |&gt; \n  mutate(parrafo = row_number())\n\n# Elimina los espacios en blanco al principio y\n# al final del texto\ndx$texto &lt;- trimws(dx$texto)\n\n# Selecciona solo las variables.de inter√©s\ndx &lt;- dx[,c(\"parte\",\n            \"capitulo\",\n            \"parrafo\",\n            \"texto\")]\n\n\n# Visualiza los resultados\nlibrary(reactable)\nreactable(dx, \n          resizable = T, \n          wrap = F)\n\n\n\n\n\n\nEl paso siguiente consiste en crear una versi√≥n distinta del mismo texto. Pero ahora, la novela ser√° dividida de forma que cada observaci√≥n en la base de datos corresponder√° a un cap√≠tulo completo:\n\n\nC√≥digo\n# Genera una base de datos agregada\n# por cap√≠tulo (y no por p√°rrafo, como\n# la anterior)\ndc &lt;- aggregate(\n          list(texto=dx$texto), \n          by=list(parte=dx$parte,\n                  capitulo=dx$capitulo), \n          FUN=paste, \n              collapse=\"\\n\\n\")\n\n# Visualiza los resultados\nreactable(dc, \n          resizable = T, \n          wrap = F)\n\n\n\n\n\n\nFinalmente, estandarizamos los nombres de las dos bases de datos y, a continuaci√≥n, las guardamos en un archivo de R que ser√° empleado en los an√°lisis:\n\n\nC√≥digo\n# Estandariza los nombres de las\n# bases de datos\nregp &lt;- dx\nregc &lt;- dc\n\n# Guarda los resultados\n# Elegid una ubicaci√≥n en vuestro\n# ordenador donde pod√°is rescatar\n# los datos luego:\n# \"C:/FiloR/Regenta.RData\", por ejemplo\nsave(regp, regc, file=\"textos/Regenta.RData\")\n\n\n¬øPor qu√© estandarizamos los nombres? Una de las grandes ventajas de utilizar R se encuentra en su facilidad de manejo de diversas bases de datos de forma simult√°nea. Por ello, es importante que los nombres de las bases de datos sean f√°ciles de recordar y de escribir. Adem√°s, es importante que los nombres sean descriptivos, para que se pueda recordar f√°cilmente qu√© contiene cada base de datos. Cuando trabajemos m√°s tarde con esas bases, sabremos que regp contiene los p√°rrafos de ‚ÄúLa Regenta‚Äù y que regc contiene los cap√≠tulos de ‚ÄúLa Regenta‚Äù. Haremos algo semejante para la obra teatral.\n\n\nC√≥digo como modelo\nEl c√≥digo anterior es un modelo que puede ser empleado para el tratamiento de cualquier texto con una estructura semejante a de una novela. Para ello, solo es necesario cambiar la direcci√≥n del texto original y ajustar los nombres de las partes y cap√≠tulos. Adem√°s, es posible modificar el c√≥digo para que se ajuste a las necesidades de cada texto. Por ejemplo, si el texto original no tiene partes, se puede eliminar el segmento de c√≥digo responsable de la divisi√≥n en partes. O si el texto no tiene cap√≠tulos, se puede eliminar la secci√≥n relativa a la divisi√≥n en cap√≠tulos.\nNo hay un c√≥digo √∫nico que sea v√°lido para todos los textos. Por ello, es necesario adaptar el c√≥digo a las caracter√≠sticas de cada texto. Sin embargo, el c√≥digo presentado aqu√≠ es un buen punto de partida para el tratamiento de cualquier texto con una estructura de partes o cap√≠tulos.\nComo ejercicio, se podr√≠a intentar aplicar el c√≥digo a ‚ÄúDon Quijote‚Äù, por ejemplo. Su c√≥digo en el Projecto Gutenberg es 2000.",
    "crumbs": [
      "Preparaci√≥n"
    ]
  },
  {
    "objectID": "prepa.html#tres-sombreros-de-copa-red-de-di√°logos",
    "href": "prepa.html#tres-sombreros-de-copa-red-de-di√°logos",
    "title": "Preparaci√≥nPreparaci√≥n de los textos en R",
    "section": "Tres sombreros de copa: red de di√°logos",
    "text": "Tres sombreros de copa: red de di√°logos\n\nEstructura de la base de datos\nEn el caso de una obra de teatro, la estructura de la base de datos es diferente. En lugar de tomos y cap√≠tulos, tenemos actos y escenas. Adem√°s, en lugar de p√°rrafos, tenemos di√°logos. Existen marcadores claros que nos permiten identificar cada una de las partes.\nPor su misma estructura, adem√°s, las obras de teatro son excelente material para la realizaci√≥n de determinados an√°lisis como el an√°lisis de redes sociales (SNA, en su sigla en ingl√©s). Tambi√©n permiten otros tipos de agregaci√≥n, como, por ejemplo, por personaje o por acto. De ese modo, es posible analizar las diferencias en t√©rminos de lenguaje, vocabulario o temas. Aunque se pueda hacer algo parecido con una novela, el proceso de identificaci√≥n del di√°logo de cada personaje resulta significativamente m√°s laborioso cuando comparado con una pieza teatral.\nEn el caso de la obra de teatro, obtendremos tres bases de datos. La primera contendr√° los datos del acto, personaje que habla, personaje a quien destina su habla, el orden del di√°logo en la obra y el texto del di√°logo.\nLa segunda y tercera base de datos estar√°n conformadas por una lista de v√≠nculos entre pares de personajes y el n√∫mero de veces que se comunican de forma dirigida y no dirigida.\nUna red dirigida es aquella en la que se establece una relaci√≥n de un nodo a otro que puede ser asim√©trica. En este caso, la direcci√≥n importa. En este caso, el personaje A se dirige al personaje B. El primero es activo y el segundo pasivo y ni siempre existe una correspondencia perfecta o sim√©trica.\nSin embargo, en una red no dirigida, la relaci√≥n es rec√≠proca o la direcci√≥n indeterminada. No consideramos qui√©n habla con qui√©n, sino la intensidad de su v√≠nculo o el total de veces que han interactuado.\nPensemos en un ejemplo claro extra√≠do de las redes sociales. No es lo mismo seguir a Rosal√≠a o cualquier persona famosa que ser seguido por una de ellas. En una red no dirigida, solo sabemos que existe un v√≠nculo entre dos personas, pero no sabemos qui√©n es el que sigue el otro. En una dirigida, tenemos una informaci√≥n vital que nos permite entender mejor la importancia de cada nodo en la red.\nCada una de esas formas de tratar el v√≠nculo entre los personajes nos ofrece informaci√≥n distinta sobre el rol y la importancia de cada uno de ellos en la obra. Por lo tanto, nos interesa tener ambas redes para analizarlas y compararlas.\nPara ello, emplearemos la obra ‚ÄúTres sombreros de copa‚Äù de Miguel Mihura. Se trata de una pieza en tres actos con 18 personajes. No presenta una estructura compleja, lo que facilita el tratamiento de los datos.\n\n\nDe di√°logos a datos\nEl primer paso es leer el texto de la obra. Aqu√≠ transformaremos los di√°logos en datos que puedan, luego, ser sometidos a an√°lisis. Empezamos por leer el texto de la obra. Para ello, emplearemos la funci√≥n pdf_text del paquete pdftools. A continuaci√≥n, eliminaremos los espacios en blanco m√∫ltiples entre palabras y las cabeceras.\n\n\nC√≥digo\n# Carga los paquetes necesarios\n# para el tratamiento de los textos\nlibrary(pdftools)   # Lee el pdf original de la obra\nlibrary(readr)      # Lee las l√≠neas del texto \nlibrary(stringi)    # Funciones de manipulaci√≥n de texto\n\n# Lee el pdf de la obra de Mihura\npd &lt;- pdf_text(\"https://www.edu.xunta.gal/centros/cpilorenzobaleiron/system/files/u2/mihura__miguel_-_tres_sombreros_de_copa.pdf\")\n\n# Elimina los espacios en blanco m√∫ltiples entre\n# palabras\npx &lt;- read_lines(pd)\npx &lt;- trimws(px)\npx &lt;- gsub(\"\\\\s+\",\" \", px, perl = T)\n\n# Elimina las cabeceras de las p√°ginas y los\n# n√∫meros de p√°gina del PDF \nnn &lt;- which(px%in%c(\"3 sombreros de copa Miguel Mihura\"))\npd &lt;- px[-c(nn-1,nn)]\n\n# Elimina el n√∫mero de la √∫ltima p√°gina\npd &lt;- pd[-length(pd)]\n\n# Hace una modificaci√≥n del texto para\n# facilitar el reconocimiento de uno\n# de los personajes\npd &lt;- stri_replace_all_fixed(pd, \"EL ODIOSO SE√ëOR,\",\"\\nEL ODIOSO SE√ëOR.\")\n\n\nEn el siguiente paso, toca separar los di√°logos de los personajes. Emplearemos una expresi√≥n regular que identifica los nombres de los personajes y los separa de los di√°logos creando un prefijo ‚ÄúPERSONA-‚Äù para identificar m√°s f√°cilmente qu√© l√≠neas corresponden al nombre del interlocutor.\nEn la pieza, los nombres de los personajes se identifican por una o varias palabras en may√∫sculas que inician la frase seguidas de un punto, un espacio y, luego, son sucedidas por el texto. Por ejemplo, ‚ÄúDIONISIO. No.¬†No veo nada.‚Äù o ‚ÄúDON ROSARIO. Parece usted tonto, don Dionisio.‚Äù nos informan un patr√≥n claro. El objetivo es cortar el texto en dos partes: una con el nombre del personaje y otra con el di√°logo.\n\n\nC√≥digo\n# Identifica las l√≠neas que contienen los nombres\n# de los personajes y las separa de los di√°logos\npx &lt;- stri_replace_all_regex(pd,\"^([[A-Z|\\\\p{Lu}]+\\\\s{1,1}[A-Z|\\\\p{Lu}]+]+)(\\\\.\\\\s{1,1})\",\"\\n\\nPERSONA-$1$2\\n\\n\") \n\n\nComo en el caso de la novela, empleamos una expresi√≥n regular para identificar los nombres y separarlos de los textos.\n\n^ indica que la expresi√≥n regular buscar√° todo que comience una l√≠nea con las caracter√≠sticas a continuaci√≥n.\n[A-Z|\\\\p{Lu}]+ busca una o m√°s letras en may√∫sculas que puedan contener textos con tilde.\n\\\\s{1,1} busca un espacio en blanco.\n[A-Z|\\\\p{Lu}]+ busca una o m√°s letras en may√∫sculas que puedan contener textos con tilde.\n\nComo pod√©is ver, la segunda expresi√≥n se repite, pues los nombres, que est√°n en may√∫sculas en la edici√≥n elegida, pueden estar compuestos por m√°s de una palabra. Tambi√©n vemos que todo ese conjunto se encuentra dentro de un grupo []+ que indica que puede haber una o m√°s repeticiones de ese conjunto, es decir, varias palabras en may√∫sculas separadas por un espacio.\nEl segundo grupo de la expresi√≥n regular, (\\\\.\\\\s{1,1}), busca un punto seguido seguido de un espacio en blanco.\nAs√≠ que, en resumen, la expresi√≥n regular busca una o m√°s palabras en may√∫sculas que inicien una l√≠nea y est√©n seguidas de un punto y un espacio en blanco. Este es el patr√≥n que buscamos identificar.\nLa segunda a√±ade dos saltos de l√≠nea (\\n\\n) y la f√≥rmula PERSONA- antes de repetir los valores encontrados ($1$2) y, luego, introducir otros dos saltos de l√≠nea (\\n\\n) para separar el nombre del personaje del texto del di√°logo.\nNuestros ejemplos quedar√≠an as√≠:\nOriginal: ‚ÄúDIONISIO. No.¬†No veo nada.‚Äù\nModificado: ‚Äú\\n\\nPERSONA-DIONISIO.\\n\\nNo. No veo nada.‚Äù\nOriginal: ‚ÄúDON ROSARIO. Parece usted tonto, don Dionisio.‚Äù\nModificado: ‚Äú\\n\\nPERSONA-DON ROSARIO.\\n\\nParece usted tonto, don Dionisio.‚Äù\nAl ejecutar la funci√≥n read_lines() justo en seguida, el nombre y el textos quedan separados.\nEn el c√≥digo abajo realiza justamente dicha tarea y, adem√°s, elimina los saltos de l√≠nea que se encuentran en medio de los di√°logos.\n\n\nC√≥digo\n# Elimina los saltos de l√≠nea en los di√°logos\npx &lt;- read_lines(px)\npd &lt;- paste(px, collapse = \"\\n\")\npx &lt;- stri_replace_all_regex(pd,\"(\\\\S|\\\\p{L})(\\n|\\n\\n)(\\\\S{1}|\\\\p{L})\",\"$1 $3\")\npd &lt;- read_lines(px)\n\n\nCon esto resuelto, obtenemos la descripci√≥n y los √≠ndices de los actos y personajes. Se emplear√°n luego para la creaci√≥n de la base de datos con los di√°logos.\n\n\nC√≥digo\n# Identifica los actos\nna &lt;- which(stri_detect_regex(pd, \"^ACTO\")==TRUE)\nta &lt;- pd[na]\n\n# Identifica los personajes\nnp &lt;- which(stri_detect_regex(pd, \"^PERSONA-\")==TRUE)\npp &lt;- pd[np]\n\n\nComo en ‚ÄúLa Regenta‚Äù, se crean variables o vectores que repiten el t√≠tulo del acto y el nombre del personaje para cada di√°logo.\n\n\nC√≥digo\n# Atribuye una secci√≥n inicial de pre√°mbulo\n# para la presentaci√≥n de personajes y\n# la descripci√≥n de la escena inicial\npt &lt;- rep(\"Preambulo\",length(1:(na[1]-1)))\n\n# Para cada acto, se asigna el t√≠tulo del acto\nfor(i in 1:(length(na)-1)){\n  \n  na[i+1]-na[i]  \n\n  pt &lt;- c(pt,rep(ta[i],length((na[i]):(na[i+1]-1))))\n    \n}\n\n# Identifica el √∫ltimo acto\npt &lt;- c(pt, rep(ta[length(na)],length((na[length(na)]):length(pd))))\n\n# Atribuye una secci√≥n inicial de introducci√≥n\npe &lt;- rep(\"Introducci√≥n\",length(1:(np[1]-1)))\n\n# Para cada personaje, se asigna el nombre del personaje\nfor(i in 1:(length(np)-1)){\n  \n  np[i+1]-np[i]  \n  \n  pe &lt;- c(pe,rep(pp[i],length((np[i]):(np[i+1]-1))))\n  \n}\n\npe &lt;- c(pe, rep(pp[length(np)],length((np[length(np)]):length(pd))))\n\n\nCon todas las variables a mano:\n\nlas juntamos en una base de datos;\neliminamos las l√≠neas vac√≠as y;\neliminamos di√°logos que contienen el nombre del acto.\n\n\n\nC√≥digo\n# Convierte en una base de datos\ndd &lt;- data.frame(pt, pe, pd)\ndd &lt;- dd[dd$pd!=\"\",]\ndd &lt;- dd[dd$pe!=dd$pd,]\n\n\nPara garantizar que podamos regresar en cualquier momento a la secuencia original de los di√°logos, creamos una variable que ordene los di√°logos en el orden en que aparecen en la obra. No obstante, a veces, existe m√°s de una l√≠nea de di√°logo por personaje. El orden debe llevar en cuenta esta peculiaridad.\n\n\nC√≥digo\n# Define un orden para los\n# di√°logos\ndd$ord &lt;- NA\ndd$px &lt;- paste0(dd$pt,\" - \", dd$pe)\n\n# Para cada di√°logo\nfor(i in 1:nrow(dd)){\n  \n  # Establece el orden del dialogo\n  # de forma secuencial\n  dd$ord[i] &lt;- i\n  \n  # Si es el segundo di√°logo o posterior\n  if(i&gt;1){\n    \n    # Si el personaje es el mismo\n    if(dd$px[i]==dd$px[i-1]){\n      \n      # Mantiene el mismo orden del\n      # personaje anterior\n      dd$ord[i] &lt;- dd$ord[i-1]\n      \n    # Caso contrario\n    }else{\n      # Aumenta el orden del personaje\n      # (orden del anterior m√°s uno)\n      dd$ord[i] &lt;- dd$ord[i-1]+1 \n    }\n  }\n  \n}\n\n\nEstamos casi ya. Ahora, juntamos el texto de un mismo personaje, en el mismo orden dentro de un acto, en un solo di√°logo. De esa manera, evitamos m√∫ltiples observaciones que, en realidad, dicen respeto a la misma unidad de an√°lisis.\n\n\nC√≥digo\n# Fusiona el texto de un mismo personaje \n# en un mismo dialogo\nag &lt;- aggregate(list(dialogo=dd$pd), \n                by=list(acto=dd$pt,\n                        personaje_A=dd$pe,\n                        orden=dd$ord), \n                FUN=paste, \n                collapse=\"\\n\")\n\n\nEl paso final consiste en eliminar la informaci√≥n innecesaria, como retirar el prefijo ‚ÄúPERSONA-‚Äù que hemos empleado como ayuda, y visualizar los resultados.\n\n\nC√≥digo\n# Elimina informaci√≥n innecesaria\nag$personaje_A[grep(\"ACTO\",ag$dialogo)] &lt;- \"Introducci√≥n\"\nag$personaje_A&lt;-gsub(\"PERSONA-\",\"\",ag$personaje_A)\nag$personaje_A&lt;-gsub(\"\\\\.\",\"\",ag$personaje_A)\n\n# Vemos el resultado\nreactable(ag, resizable = T, wrap = F)\n\n\n\n\n\n\n\n\nDe datos a redes de di√°logos\nPara transformar la base de datos en una red de di√°logos, necesitamos identificar los personajes que dialogan entre s√≠. Para ello, creamos una variable que identifique el personaje que responde al interlocutor anterior. En muchas ocasiones, el di√°logo se interrumpe por distintas razones, como la entrada de un nuevo personaje, el cambio de escena o el fin de un acto. En estos casos, no podemos considerar que el di√°logo anterior contin√∫a. Por lo tanto, necesitamos identificar estos puntos de corte.\nLa manera m√°s f√°cil es realizar una lectura r√°pida de los di√°logos para identificar estos puntos. Abajo, creamos en la base de datos una nueva variable llamada ‚Äúcorte‚Äù que identifica tales puntos y nos permitir√°n establecer de forma correcta el sentido del di√°logo y sus interlocutores.\n\n\nC√≥digo\n# Identifica los puntos de corte en los di√°logos\n# que corresponden a transiciones de escena o\n# cu√°ndo sale uno o m√°s personajes y se empieza\n# otro dialogo o se trata de una respuesta al \n# interlocutor anterior que no obtiene respuesta\n# y se pasa a un nuevo di√°logo con otro personaje. \n# Por lo tanto, no se puede considerar\n# como una continuaci√≥n del dialogo anterior.\nnc &lt;- c(2,112,177,208,211,217,268,338,365,372,378, \n        380, 388,399,417,428,439,445, 448,452,463,\n        469,480,494,495,594,599,605,653,661,673,675,\n        745,824,825,834,837,855,864)\n\n# Crea una variable corte con valor cero\n# para todos los di√°logos\nag$corte &lt;- 0\n\n# En aquellos di√°logos que representan\n# un corte, cambia de cero a uno para\n# establecer el punto de interrupci√≥n\nag$corte[nc] &lt;- 1\n\n\nEl siguiente paso resulta crucial. Necesitamos identificar el personaje al que se dirige el di√°logo. Para ello, creamos una nueva variable en la base de datos llamada ‚Äúpersonaje_B‚Äù que identificar√° dicho interlocutor. En este momento, emplearemos los puntos de interrupci√≥n o corte en los di√°logos para determinar de forma correcta a qui√©n se destina el habla.\n\n\nC√≥digo\n# Crea una variable vac√≠a en la base de\n# datos para almacenar el personaje\n# que ser√° el receptor de la respuesta\nag$personaje_B &lt;- NA\n\n# Para cada di√°logo de la pieza\nfor(i in 1:(nrow(ag)-1)){\n  \n  # Si es la introducci√≥n del capitulo o de la obra,\n  # se pasa al siguiente di√°logo\n  if(ag$personaje_A[i]==\"Introducci√≥n\") next\n\n  # Si se trata de un corte o fin de escena\n  # se considera como respuesta al personaje\n  # anterior (si no es la introducci√≥n de la escena)\n  if(ag$corte[i]==1){\n    \n    # Si el personaje anterior es la introducci√≥n\n    # se pasa al siguiente di√°logo\n    if(ag$personaje_A[i-1]==\"Introducci√≥n\") next\n    \n    # Atribuye el personaje de destino del di√°logo\n    # como en personaje anterior (respuesta final)\n    ag$personaje_B[i] &lt;- ag$personaje_A[i-1]\n    \n  # En caso que no sea un corte de escena  \n  }else{ \n    # El personaje de destino del di√°logo\n    # es el inmediatamente posterior\n    ag$personaje_B[i] &lt;- ag$personaje_A[i+1]\n  }\n}\n\n# Hay un pasaje en el que Sagra, Carmela y\n# Trudy se dirigen a Fanny, por eso resulta\n# necesario corregir el personaje de destino\nag$personaje_B[c(339:355,357:365)] &lt;- \"FANNY\"\n\n# La respuesta de Fanny\nag$personaje_B[c(356)] &lt;- \"LAS TRES\"\n\n# Otra correcci√≥n puntual\nag$personaje_B[c(825)] &lt;- \"DIONISIO\"\n\n# Elimina los espacios en blanco al \n# final de los nombres de los personajes\nag$personaje_A &lt;- trimws(ag$personaje_A)\nag$personaje_B &lt;- trimws(ag$personaje_B)\n\n\nFinalmente, creamos la red de di√°logos. Ya tenemos una variable con el que habla (personaje_A) y con qui√©n dialoga (personaje_B). A continuaci√≥n, crearemos una variable para contar cu√°ntas veces hablan entre s√≠ cada par de personajes y sumamos todos. El resultado es una red dirigida de di√°logos.\n\n\nC√≥digo\n# Separa solo los pares de personaje\n# en di√°logo\nres &lt;- ag[,c(\"personaje_A\",\"personaje_B\")]\nres &lt;- res[! is.na(res$personaje_B),]\n\n# Crea un contador para saber\n# cu√°ntas veces cada par de personajes\n# ha dialogado\nres$veces &lt;- 1\n\n# Elimina la introducci√≥n como personaje\n# de los dos tipos de red\nres &lt;- res[res$personaje_A!=\"Introducci√≥n\",]\nres &lt;- res[res$personaje_B!=\"Introducci√≥n\",]\n\n# Guarda los resultados en un nuevo\n# objeto para crear una red no\n# direccional\nrea &lt;- res\n\n# Suma las veces en que se repiten\n# los pares de personajes (red dirigida)\nres &lt;- aggregate(list(freq=res$veces),\n                 by=list(personaje_A=res$personaje_A,\n                         personaje_B=res$personaje_B),\n                 FUN=sum)\n\n# ordena en orden decendiente por la frecuencia \n# en que dialogan \nres &lt;- res[order(res$freq, decreasing = T),]\n\n# Vemos el resultado\nreactable(res, resizable = T, wrap = F)\n\n\n\n\n\n\nComo podemos observar, la pareja Dionisio-Paula es la que m√°s dialoga en la obra. Viene seguida de las d√≠adas Dionisio-Don Rosario y Paula-El Odioso Se√±or. Los di√°logos entre esos cuatro personajes superan el 60% de todas las interacciones en la pieza. Pero ya nos vamos adelantando con el an√°lisis.\nConcentr√©monos ahora en la creaci√≥n de la red no dirigida. Se trata de la √∫ltima etapa en la preparaci√≥n de los datos. Como ya hemos mencionado, tambi√©n nos interesa saber cu√°ntas veces han dialogado dos personajes sin importar qui√©n es el que inicia la conversaci√≥n.\n\n\nC√≥digo\n# Carga el paquete necesario para lidiar con\n# grafos\nlibrary(igraph)\n\n# Uniformiza los valores duplicados\n# (Dionisio-Paula y Paula-Dionisio, \n# por ejemplo, se convierten todos \n# en Dionisio-Paula)\n\n# 1) Crea un grafo NO DIRECCIONAL a partir de \n# la red de personajes\ng &lt;- graph_from_data_frame(\n            rea[,c(\"personaje_A\",\"personaje_B\")], \n            directed=FALSE)\n\n# 2) Simplifica la estructura para hacer con que\n# todos los valores est√©n en una sola direcci√≥n\n# pero sin remover los repetidos, pues queremos\n# contarlos\ng &lt;- simplify(g, \n              remove.multiple = F, \n              remove.loops = F)\n\n# Convierte la red en una base de datos\nax &lt;- igraph::as_data_frame(g)\n\n# Cuenta cu√°ntas veces se repite cada par\nax$freq &lt;- 1\n\n# Suma las veces en que se repiten\n# los pares de personajes (red no dirigida)\naa &lt;- aggregate(list(freq=ax$freq),\n                by=list(personaje_A=ax$from,\n                        personaje_B=ax$to),\n                FUN=sum)\n\n# Ordena los resultados en orden descendente\naa &lt;- aa[order(aa$freq, decreasing = T),]\n# Vemos los resultados\nreactable(aa, resizable = T, wrap = F)\n\n\n\n\n\n\nFinalmente, estandarizamos los nombres de las bases de datos y las guardamos en un archivo de R.\n\n\nC√≥digo\n# Estandariza los nombres de las bases \n# de datos\n\n# Tres sombreros de copa - dialogos\ntsc_d &lt;- ag    \n\n# Tres sombreros de copa - red de personajes (no dirigida)\ntsc_rn &lt;- aa   \n\n# Tres sombreros de copa - red de personajes (dirigida)\ntsc_rd &lt;- res  \n\n# Guarda los resultados\n# Elegid una ubicaci√≥n en vuestro\n# ordenador donde pod√°is rescatar\n# los datos luego:\n# \"C:/FiloR/Tres_sombreros_de_copa.RData\", \n# por ejemplo\nsave(tsc_d, \n     tsc_rd, \n     tsc_rd, \n     file=\"textos/Tres_sombreros_de_copa.RData\")",
    "crumbs": [
      "Preparaci√≥n"
    ]
  },
  {
    "objectID": "regenta.html",
    "href": "regenta.html",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "",
    "text": "En este apartado, se analiza la obra ‚ÄúLa Regenta‚Äù de Leopoldo Alas Clar√≠n a partir de diferentes t√©cnicas de an√°lisis de contenido. Se tratan, en su mayor parte, de acercamientos estad√≠sticos o cuantitativos a los textos literarios. Por lo tanto, representan una visi√≥n limitada de la obra y solo complementaria a la lectura y el an√°lisis cualitativo detenido de la misma.\nNos acercaremos al texto, primero, intentando descubrir cu√°les palabras se destacan, sus frecuencias y distribuciones. Luego, analizaremos la obra desde la perspectiva de los personajes, sus relaciones y sus apariciones en la obra.",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "regenta.html#introducci√≥n",
    "href": "regenta.html#introducci√≥n",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "",
    "text": "En este apartado, se analiza la obra ‚ÄúLa Regenta‚Äù de Leopoldo Alas Clar√≠n a partir de diferentes t√©cnicas de an√°lisis de contenido. Se tratan, en su mayor parte, de acercamientos estad√≠sticos o cuantitativos a los textos literarios. Por lo tanto, representan una visi√≥n limitada de la obra y solo complementaria a la lectura y el an√°lisis cualitativo detenido de la misma.\nNos acercaremos al texto, primero, intentando descubrir cu√°les palabras se destacan, sus frecuencias y distribuciones. Luego, analizaremos la obra desde la perspectiva de los personajes, sus relaciones y sus apariciones en la obra.",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "regenta.html#las-palabras-que-cuentan",
    "href": "regenta.html#las-palabras-que-cuentan",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "Las palabras que cuentan",
    "text": "Las palabras que cuentan\nEl primer paso del an√°lisis consiste en cargar los datos que hemos preparado en la secci√≥n de preparaci√≥n de los datos y convertirlo en un objeto de tipo corpus. Para ello, emplearemos el paquete de R llamado quanteda, que resulta bastante completo para el an√°lisis de contenido.\nEl c√≥digo abajo carga los datos en la memoria, los convierte en un corpus y muestra algunas estad√≠sticas b√°sicas de los cap√≠tulos de la obra, como el n√∫mero de palabras (tokens), el n√∫mero de palabras √∫nicas (types) y la cantidad de frases.\n\n\nC√≥digo\n# carga los datos de \"La Regenta\"\n# Aqu√≠ buscar los datos en la \n# carpeta que hab√©is guardado los \n# datos al ejecutar los c√≥digos\n# de preparaci√≥n, algo como\n# \"C:/FiloR/Regenta.RData\", por ejemplo\nload(\"../textos/Regenta.RData\")\n\n# carga el paquete quanteda para \n# algunos an√°lisis\nlibrary(quanteda)\n\n# carga el paquete reactable que\n# permitir√° mostrar los resultados en\n# una tabla interactiva\nlibrary(reactable)\n\n# Elimina el t√≠tulo y el pr√≥logo\nregc &lt;- regc[3:nrow(regc),]\n\n# convierte en un documento corpus\ncp &lt;- corpus(regc, text_field = \"texto\")\n\n# define los cap√≠tulos como nombre\n# de los documentos\ndocnames(cp) &lt;- regc$capitulo\n\n# muestra estad√≠sticas b√°sicas de\n# cada cap√≠tulo\nreactable(summary(cp))\n\n\n\n\n\n\n\nVemos que los treinta cap√≠tulos de la obra tienen una extensi√≥n que va de poco m√°s de ocho mil hasta aproximadamente veinti√∫n mil palabras. No resulta nada sorprendente que las palabras √∫nicas y el n√∫mero de frases var√≠en de forma proporcional.\n\nFrecuencias de palabras\nEl pr√≥ximo paso consiste en convertir el corpus en una matriz de t√©rminos. Para ello, primero convertimos los textos en tokens, que son las palabras individuales de los textos. Luego, eliminamos las palabras vac√≠as (stopwords) y las palabras que no aportan informaci√≥n, como los n√∫meros y los signos de puntuaci√≥n. Este objeto ser√° luego empleado en diversas t√©cnicas de an√°lisis de contenido.\n\n\nC√≥digo\n# convierte en tokens y remueve\n# punctuaci√≥n, s√≠mbolos y n√∫meros\ntk &lt;- tokens(cp, remove_punct = TRUE, \n                  remove_numbers = TRUE, \n                  remove_symbols = TRUE)\n\n# Elimina las palabras vac√≠as\ntk &lt;- tokens_remove(tk, stopwords(\"es\"))\n\n\n\nPara poder explorar cu√°les palabras se destacan en la obra podemos emplear una t√©cnica llamada an√°lisis de frecuencia de palabras. En este caso, crearemos una matriz de t√©rminos de documentos (document-feature matrix), que es una representaci√≥n matricial de los textos en la que las filas representan los documentos y las columnas las palabras. Cada celda de la matriz contiene el n√∫mero de veces que una palabra aparece en un documento.\nEl c√≥digo abajo crea la matriz y convierte todos los t√©rminos en min√∫sculas para facilitar el cuenteo. Luego, muestra las cincuenta palabras m√°s frecuentes en la obra.\n\n\nC√≥digo\n# convierte en una matriz de t√©rminos\ndtm &lt;- dfm(tk, \n           tolower = TRUE)\n\n# muestra las 50 palabras m√°s frecuentes\ntopfeatures(dtm, 50)\n\n\n      don        si       ana     usted magistral   aquella     aquel    √°lvaro \n     1789      1164       894       822       767       758       731       488 \n   v√≠ctor      casa   regenta     se√±or   vetusta      all√≠       ser   despu√©s \n      487       477       467       458       455       446       430       415 \n    dec√≠a      do√±a       vez     mes√≠a     pod√≠a     ahora      bien      ojos \n      414       411       390       372       368       361       349       346 \n   ferm√≠n       as√≠       iba       dos    quer√≠a      dijo   siempre     menos \n      345       344       333       330       328       325       325       322 \n    mismo    hombre       tan      vida      dios     veces quintanar     mundo \n      318       314       312       311       309       305       303       285 \n    mujer     todas     sab√≠a       ver    tiempo      alma       d√≠a   parec√≠a \n      284       279       279       279       278       275       271       267 \n     amor   aquello \n      267       265 \n\n\n\nEn este caso, hemos considerado palabras aisladas, pero podemos repetir el an√°lisis con bigramas o trigramas, que son secuencias de dos o tres palabras consecutivas. Estas combinaciones permiten encontrar secuencias de ideas que pueden revelar ciertos contenidos o patrones en el texto.\n\n\nC√≥digo\n# Crea bigramas\nbi &lt;- tokens_ngrams(tk, n = 2)\n\n# convierte en una matriz de t√©rminos\ndtm &lt;- dfm(bi)\n\n# muestra los 50 bigramas m√°s frecuentes\ntopfeatures(dtm, 50)\n\n\n     don_v√≠ctor      don_√°lvaro      don_ferm√≠n     don_pompeyo      do√±a_paula \n            450             390             302             123             119 \n        tal_vez      don_santos  do√±a_petronila      don_carlos   aquella_noche \n            105              93              66              60              51 \n  aquel_momento    don_custodio        do√±a_ana    do√±a_anuncia        cada_vez \n             48              47              47              47              46 \n   don_cayetano   aquella_tarde      don_frutos     do√±a_camila se√±or_magistral \n             46              45              43              38              37 \n   aquel_hombre   don_saturnino        dos_tres  don_robustiano     don_saturno \n             36              35              34              34              32 \n    pocas_veces    todas_partes    muchas_veces     usted_se√±or        cada_d√≠a \n             32              31              31              31              30 \n  aquella_mujer        si_usted       aquel_d√≠a       pod√≠a_ser        don_juan \n             30              30              29              29              29 \n       voz_baja       deb√≠a_ser     do√±a_rufina       buen_mozo      ana_ozores \n             28              28              28              27              26 \n  d√≠a_siguiente    √°lvaro_mes√≠a  caser√≥n_ozores      aire_libre      mire_usted \n             26              26              26              25              25 \n   santa_teresa    mundo_entero  cualquier_cosa     do√±a_√°gueda       se√±or_don \n             25              24              24              24              23 \n\n\nC√≥digo\n# Crea trigramas\ntri &lt;- tokens_ngrams(tk, n = 3)\n\n# convierte en una matriz de t√©rminos\ndtm &lt;- dfm(tri)\n\n# muestra los 50 trigramas m√°s frecuentes\ntopfeatures(dtm, 50)\n\n\n         don_√°lvaro_mes√≠a      don_pompeyo_guimar√°n      don_v√≠ctor_quintanar \n                       22                        20                        17 \n   don_saturnino_berm√∫dez       don_santos_barinaga        don_frutos_redondo \n                       16                        13                        11 \n      casa_do√±a_petronila            dos_tres_veces          dio_media_vuelta \n                       11                         9                         9 \n          do√±a_ana_ozores             si_don_v√≠ctor                  ta_ta_ta \n                        8                         8                         8 \n          casa_don_v√≠ctor         darse_cuenta_ello             don_√°lvaro_si \n                        8                         8                         8 \n do√±a_petronila_rianzares            don_ferm√≠n_pas      jefe_partido_liberal \n                        8                         7                         7 \npartido_liberal_din√°stico          don_tom√°s_crespo        almunia_don_godino \n                        7                         7                         7 \n       hermano_mayor_alma            _la_cruz_roja_     don_robustiano_somoza \n                        7                         7                         7 \n                 ja_ja_ja        media_hora_despu√©s            fray_luis_le√≥n \n                        7                         7                         6 \n         don_juan_tenorio          dec√≠a_don_√°lvaro            dio_paso_atr√°s \n                        6                         6                         6 \n           ana_don_√°lvaro           dijo_don_v√≠ctor             si_don_√°lvaro \n                        6                         6                         6 \n don_custodio_beneficiado          se√±or_don_ferm√≠n          grit√≥_don_v√≠ctor \n                        5                         5                         5 \n        daba_media_vuelta    hago_cuesti√≥n_personal          aquel_don_√°lvaro \n                        5                         5                         5 \n         usted_se√±or_foja             dijo_voz_baja            don_v√≠ctor_vio \n                        5                         5                         5 \n         pobre_don_santos        treinta_cinco_a√±os  beneficiado_don_custodio \n                        5                         4                         4 \n        hablaban_voz_baja   visitaci√≥n_ol√≠as_cuervo     don_restituto_mourelo \n                        4                         4                         4 \n         primera_vez_vida          se√±or_don_v√≠ctor \n                        4                         4 \n\n\n\n¬øQu√© vemos en los resultados de los bigramas y trigramas? El primer patr√≥n que emerge es la presencia de nombres de personajes, como ‚Äúdon V√≠ctor Quintanar‚Äù, ‚Äúdon √Ålvaro‚Äù o ‚Äúdo Ferm√≠n‚Äù. Tambi√©n aparecen nombres de lugares, como ‚ÄúVetusta‚Äù o ‚ÄúSanta Cruz‚Äù. Por √∫ltimo, encontramos algunas secuencias que parecen describir acciones o situaciones, como ‚Äúse√±or marqu√©s‚Äù o ‚Äúse√±or don Ferm√≠n‚Äù.\n\n\nColocaciones\nOtro recurso √∫til a la hora de explorar los t√©rminos m√°s frecuentes en un texto proviene de las colocaciones. Las colocaciones son secuencias de palabras que aparecen juntas con m√°s frecuencia de lo que se esperar√≠a por azar. En otras palabras, son secuencias de palabras que tienen un significado especial o que se emplean en un contexto espec√≠fico.\nEl c√≥digo abajo emplea la funci√≥n textstat_collocations del paquete quanteda.textstats para encontrar las colocaciones m√°s frecuentes en el texto1. En este caso, hemos considerado solo las colocaciones que aparecen al menos diez veces en el texto.\n\n\nC√≥digo\n# Carga el paquete\nlibrary(quanteda.textstats)\n\n# Encuentra las colocaciones\ncol &lt;- textstat_collocations(tk, \n                             min_count = 10)\n\n# Muestra los resultados\nreactable(col, resizable = TRUE, wrap=F)\n\n\n\n\n\n\n\nComo hemos podido ver, vuelven a aparecer los nombres de los personajes, lugares, pero ahora tambi√©n llaman la atenci√≥n algunos t√©rminos que indican frecuencia (algunas veces, muchas veces, dos tres, cada d√≠a) o hacen referencia al tiempo (aquel momento, aquella tarde, media hora). Estos t√©rminos pueden ser √∫tiles para entender el contexto en el que se desarrolla la obra.\n\n\nPalabras-clave\nOtro recurso que disponemos para examinar el contenido de un texto es el an√°lisis de palabras-clave. Podemos interesarnos por un tema o concepto espec√≠fico y buscar en qu√© contexto aparece en el texto. En este caso, vamos a buscar la palabra ‚Äúadulterio‚Äù y ver en qu√© contexto aparece en la obra.\nUna estrategia ser√≠a ver cu√°ntas veces aparece ‚Äúadulterio‚Äù en la novela, pero eso no nos dar√≠a mucha informaci√≥n sobre el contexto en el que se emplea. Por eso, vamos a emplear la funci√≥n kwic (keyword in context) del paquete quanteda para buscar la palabra en el texto y ver en qu√© contexto aparece.\nEl resultado es una tabla que muestra la palabra ‚Äúadulterio‚Äù y las palabras que la rodean en el texto. De esta manera, podemos entender mejor c√≥mo se emplea la palabra en la obra y qu√© significado tiene en el contexto de la novela.\n\n\nC√≥digo\n# Carga el paquete\nlibrary(quanteda)\n\n# recreamos los tokens\n# sin remover la puntuaci√≥n\n# o los stopwords\ntk &lt;- tokens(cp)\n\n# Busca la palabra \"adulterio\" en\n# su contexto\nkw_amor &lt;- kwic(tk, \n                pattern =  \"adulterio\")\n\n# Muestra los resultados\nreactable(kw_amor, \n          resizable = TRUE, \n          wrap=F)\n\n\n\n\n\n\n\nSaltan a la vista los calificativos y acciones que se revelan cuando se analiza el contexto de ‚Äúadulterio‚Äù. Se ven atributos como ‚Äúrepugnante‚Äù, ‚Äúinfame‚Äù, ‚Äúominoso‚Äù, ‚Äúesc√°ndalo‚Äù. Tambi√©n acciones que se asocian como respuesta al adulterio: ‚Äúvengar‚Äù, ‚Äúduelo‚Äù, ‚Äúbatirme‚Äù. En pocas palabras, se nota el rechazo social al adulterio y se puede f√°cilmente imaginar un desaforado cornudo, pistola en mano, buscando venganza.\nPodemos emplear un tipo de visualizaci√≥n de datos llamado √°rbol de palabras para representar gr√°ficamente el contexto en el que aparece la palabra ‚Äúadulterio‚Äù. En este caso, vamos a emplear la funci√≥n wordtree del paquete tenet para crear un √°rbol de palabras que muestre las palabras que aparecen antes y despu√©s de ‚Äúadulterio‚Äù en el texto. No obstante, como hemos visto, la palabra ‚Äúadulterio‚Äù no aparece muchas veces en la novela, por lo que el √°rbol de palabras no ser√° muy complejo ni tampoco interesante. Probemos algo m√°s picante, que salga el ‚Äúamor‚Äù.\n\n\nC√≥digo\nlibrary(tenet)\n\nwordtree(cp, \"amor\")\n\n\n\n\n\n  \n  \n  \n                   \n                   \n                   \n                   \n                   \n\n\n\nAhora las cosas se ponen m√°s interesantes. Vemos que las palabras cambian de tama√±o seg√∫n su frecuencia, de modo que sabemos que ‚Äúamor de‚Äù resulta m√°s com√∫n que ‚Äúamor del‚Äù, por ejemplo.\nPero, ¬øqu√© palabras debo elegir? ¬øC√≥mo s√© cu√°les son las m√°s relevantes? Para responder a estas preguntas, podemos emplear una t√©cnica llamada keyness. Esta t√©cnica compara la frecuencia de una palabra en un texto con su frecuencia en otro texto de referencia. Si la palabra aparece poco en el texto de referencia, entonces deber√≠a aparecer poco en el texto elegido. Si no es as√≠, tenemos una palabra clave, entendida como un t√©rmino cuya frecuencia resulta muy superior a la esperada.\nEl cap√≠tulo 8 de la novela es una delicia para emplear esa t√©cnica. Se trata de un pasaje que contiene la descripci√≥n de una merienda en la casa de la marquesa de Vegallana y sus ‚Äúpreparativos‚Äù en la cocina. Emplearemos la funci√≥n textstat_keyness del paquete quanteda.textstats para encontrar las palabras clave.\n\n\nC√≥digo\n# Cargamos los paquetes necesarios\nlibrary(quanteda.textstats)\nlibrary(quanteda.textplots)\n\n# Volvemos a crear los tokens\n# sin puntos ni stopwords\n\n# convierte en tokens y remueve\n# punctuaci√≥n, s√≠mbolos y n√∫meros\ntk &lt;- tokens(cp, remove_punct = TRUE, \n                  remove_numbers = TRUE, \n                  remove_symbols = TRUE)\n\n# Elimina las palabras vac√≠as\ntk &lt;- tokens_remove(tk, stopwords(\"es\"))\n\n# Creamos la matriz de frecuencia\n# de t√©rminos\ndtm &lt;- dfm(tk)\n\n# Calculamos la estad√≠stica, \n# considerando el cap√≠tulo 8 como\n# objetivo y el resto de la novela\n# como referencia\nkey &lt;- textstat_keyness(dtm, \n                        target = \"08\")\n\n# Visualizamos los resultados\ntextplot_keyness(key)\n\n\n\n\n\n\n\n\n\n\nLas palabras asociadas a la comida se destacan: cocina, despensa, cocinero, fog√≥n, pinche, merienda, alm√≠bares. Tambi√©n se destacan palabras asociadas a la nobleza: marques, marquesa, regencia, as√≠ como el lugar de las tertulias (el sal√≥n amarillo). De otro lado, vemos las palabras que est√° fuera: Magistral, Ferm√≠n, V√≠ctor, Ana, Quintanar, que son personajes que no aparecen en el cap√≠tulo 8 o apenas lo hacen.\nPodemos a√±adir informaci√≥n empleando la funci√≥n plotKeyness del paquete tenet para visualizar los resultados de una manera interactiva y bidimensional. Nos interesa saber, adem√°s del chi2, la frecuencia de las palabras. No es lo mismo una palabra rara que aparece poco que otra que no resulta tan com√∫n en la obra, pero que se emplea mucho en el cap√≠tulo en cuesti√≥n.\n\n\nC√≥digo\n# carga el paquete\nlibrary(tenet)\n\n# crea el gr√°fico\nplotKeyness(cp, \n            ref.cat= \"08\")\n\n\n\n\n\n\n\nDe ese modo, las palabras que se encuentren lo m√°s lejos del eje horizontal y vertical ser√°n las m√°s espec√≠ficas del cap√≠tulo. Por otra parte, aquellas que se encuentren m√°s a la derecha, son las m√°s frecuentes en el cap√≠tulo 8. Por lo tanto, t√©rminos como ‚Äúvisita‚Äù, ‚Äúcocina‚Äù, ‚Äúmarqu√©s‚Äù se destacan tanto por su particular incidencia en el cap√≠tulo, como por su alta frecuencia. Tambi√©n vemos en rojo las palabras menos empleadas que lo esperado.\nSi queremos analizar cu√°les son las expresiones de peso en los dem√°s cap√≠tulos, basta cambiar el argumento ref.cat por el n√∫mero del cap√≠tulo que nos interese. Estos pasos exploratorios nos permiten tener una idea de los temas y personajes que aparecen en cada cap√≠tulo y, por consiguiente, de las palabras clave que los caracterizan.",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "regenta.html#codificaci√≥n-tem√°tica",
    "href": "regenta.html#codificaci√≥n-tem√°tica",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "Codificaci√≥n tem√°tica",
    "text": "Codificaci√≥n tem√°tica\nEntendemos por codificaci√≥n tem√°tica el proceso de an√°lisis de un texto con el prop√≥sito de identificar ideas, conceptos y temas recurrentes. Se utiliza de forma amplia en las ciencias sociales, como la sociolog√≠a o la antropolog√≠a, para analizar entrevistas, encuestas o documentos. En este caso, vamos a emplear la codificaci√≥n tem√°tica para identificar los temas y conceptos que aparecen en la novela.\nComo temas, por ejemplo, podemos tener el tiempo (las estaciones del a√±o, el paso del tiempo, el momento del d√≠a, las fiestas religiosas), el espacio (el hogar, los ambientes de interacci√≥n social, la iglesia), la familia (los padres, los hijos, los hermanos), la sociedad (los nobles, los plebeyos, los campesinos), entre otros.\nLa forma m√°s ‚Äútradicional‚Äù de codificaci√≥n tem√°tica consiste en imprimir los documentos, leerlos detenidamente y realizar marcas o anotaciones en los m√°rgenes. Sin embargo, en la era digital, podemos emplear herramientas de an√°lisis de texto que nos ayudan a llevar a cabo esta tarea de forma m√°s r√°pida y eficiente. Los diccionarios (o l√©xicos) son una de las m√°s comunes.\n\nEl uso de diccionarios\nUn diccionario corresponde a un conjunto de palabras clave asociados a un tema. Por ejemplo, cuando pienso en la familia, me vienen a la mente palabras como ‚Äúpadre‚Äù, ‚Äúmadre‚Äù, ‚Äúhijo‚Äù, ‚Äúhermano‚Äù, ‚Äúhermana‚Äù,‚Äút√≠o‚Äù, ‚Äút√≠a‚Äù, ‚Äúabuelo‚Äù, ‚Äúabuela‚Äù. Algunos, m√°s radicales, incluir√≠an los cu√±ados y parientes m√°s lejanos. Si lo expresara de forma algor√≠tmica ser√≠a algo as√≠:\nfamilia = c(‚Äúpadre‚Äù, ‚Äúmadre‚Äù, ‚Äúhijo‚Äù, ‚Äúhermano‚Äù, ‚Äúhermana‚Äù, ‚Äút√≠o‚Äù, ‚Äút√≠a‚Äù, ‚Äúabuelo‚Äù, ‚Äúabuela‚Äù)\nAl buscar esas palabras en uno o varios textos, sabr√© que se menciona de alguna manera la familia y, principalmente, d√≥nde y cu√°ntas veces.\nAbajo hemos creado un diccionario con palabras clave asociadas a diferentes temas. En este caso, hemos considerado la familia, la sociedad, la iglesia, la econom√≠a, los sentimientos, el misticismo, el adulterio, el espacio y el tiempo.\nLuego, utilizo la funci√≥n tagCorpus del paquete tenet para etiquetar de forma autom√°tica los textos con las palabras clave del diccionario frase a frase. Este procedimiento tambi√©n me dice cu√°l es la categor√≠a o tema m√°s importante encontrado en la frase, cu√°les son todos los temas encontrados, la cantidad de categor√≠as y el n√∫mero de palabras clave coincidentes. Tambi√©n permite filtrar y reordenar los resultados.\n\n\nC√≥digo\n# Crea un diccionario con palabras clave\n# sobre algunos temas de inter√©s en la\n# novela\ndic &lt;- dictionary(\n  list(\n    familia=c(\"padre\", \"madre\", \"hijo\", \"hija\", \n              \"hermano\", \"hermana\"),\n    sociedad=c(\"vetustense\",\"puebl\",\"ciudad\",\"conversa\",\n               \"amig\",\"noble\",\"arist\"),\n    iglesia=c(\"cura\",\"obispo\",\"sacerdo\",\"confesi√≥n\",\n              \"religi√≥n\",\"religios\",\"can√≥nig\",\"capilla\"),\n    economia=c(\"dinero\",\"deuda\",\"negoci\",\"trabaj\",\n               \"fortuna\",\"\\\\brico\",\"\\\\brica\"),\n    sentimientos=c(\"culpa\",\"alegr\",\"\\\\bamor\\\\b\",\"remordimiento\",\n                   \"rid√≠culo\",\"verg√ºenza\",\"triste\"),\n    misticismo=c(\"Ferm√≠n de Pas\",\"Ferm√≠n\",\"\\\\bde Pas\\\\b\",\n                 \"magistral\", \"espirit\",\"dios\"),\n    adulterio=c(\"√Ålvaro\",\"Mes√≠a\",\"adulte\",\"amante\",\n                \"Presidente del\", \"marido\", \n                \"placer\", \"pasi√≥n\", \"amante\",\"amor√≠o\"),\n    espacio=c(\"casino\",\"catedral\",\"vivero\",\"\\\\bcasa\\\\b\",\n              \"espol√≥n\",\"teatro\"),\n    tiempo=c(\"oto√±o\",\"verano\",\"invierno\",\"primavera\",\n             \"semana santa\",\"navidad\",\"\\\\bd√≠a\\\\b\",\"noche\",\n             \"tarde\",\"la ma√±ana\",\"madrugada\")\n  )\n)\n    \n# Carga el paquete tenet\nlibrary(tenet)\n\n# Genera el etiquetado de \n# las frases seg√∫n el diccionario\ntagCorpus(cp, \n          dic, \n          reshape.to = \"sentence\", \n          defaultPageSize = 3)\n\n\n\n\n\n\n\nEl resultado es una lista ordenada de frases con palabras pintadas de distintos colores de acuerdo con los temas a que pertenecen, como si hubiesen sido resaltadas con un marcador. De ese modo, se pude realizar una lectura r√°pida y visual de la incidencia de los temas en el texto, manteniendo todo el contexto de la obra.\n\n\nUbicaci√≥n de temas en el texto\nLa tabla anterior resulta muy √∫til si queremos examinar las palabras en su contexto y regresar al documento para entender mejor c√≥mo se utilizan. Sin embargo, si queremos tener una visi√≥n general de la distribuci√≥n de los temas en el texto, podemos utilizar un gr√°fico de dispersi√≥n l√©xica. Se trata de una t√©cnica de visualizaci√≥n de datos que representa un texto como un intervalo cortado por puntos o l√≠neas verticales que corresponden a las palabras clave encontradas.\nLa funci√≥n plotLexDiv del paquete tenet permite generar un gr√°fico de dispersi√≥n l√©xica que muestra la distribuci√≥n de las palabras clave en el texto coloreadas por tema del diccionario. No se recomienda utilizar muchas categor√≠as en un solo gr√°fico, puesto que la visualizaci√≥n se vuelve confusa y resulta muy dif√≠cil identificar patrones.\nLos siguientes c√≥digos generan dos gr√°ficos de dispersi√≥n l√©xica, utilizando un diccionario con palabras clave asociadas a los temas de espacio y tiempo.\n\n\nC√≥digo\n# Crea un diccionario solo\n# con el tema espacio\ndicf &lt;- dictionary(\n  list(\n    espacio=c(\"casino\",\"catedral\",\"vivero\",\n              \"casa\",\"espol√≥n\",\"teatro\",\n              \"calle\",\"plaza\",\"Paseo de Verano\",\n              \"sal√≥n\",\"tertulia\")\n))\n\n# Crea el gr√°fico de dispersi√≥n\n# l√©xica\nplotLexDiv(cp, \n           dicf, \n           title ='La Regenta', \n           subtitle = \"Espacio en la novela\", \n           palette = pal$cat.brewer.Dark2.8[1])\n\n\n\n\n\n\n\n\n\n\n\nC√≥digo\n# Crea un diccionario solo\n# con el tema tiempo\ndicf &lt;- dictionary(\n  list(\n    tiempo=c(\"oto√±o\",\"verano\",\"invierno\",\"primavera\",\n             \"semana santa\",\"navidad\",\"\\\\bd√≠a\\\\b\",\"noche\",\n             \"tarde\",\"la ma√±ana\",\"madrugada\")\n))\n\n# Crea el gr√°fico de dispersi√≥n\n# l√©xica\nplotLexDiv(cp, \n           dicf, \n           title ='La Regenta', \n           subtitle = \"Tiempo en la novela\", \n           palette = pal$cat.brewer.Dark2.8[2])\n\n\n\n\n\n\n\n\n\n\nComo podemos observar, las palabras clave relacionadas al espacio y tiempo se intercalan sin presentar un patr√≥n claro, pero s√≠ es posible apreciar c√≥mo a partir del cap√≠tulo 15 las alusiones al tiempo se acrecientan, de una manera regular que se mantiene hasta el 30. Esto corrobora los an√°lisis filol√≥gicos que se han realizado sobre la estructura de la novela. Igualmente, ser√≠a √∫til realizar un an√°lisis m√°s detallado de los espacios (y de los tiempos) mencionados en la novela. Para ello, podemos utilizar la funci√≥n filterWords del paquete tenet para seleccionar solo las palabras clave relacionadas al espacio y generar un gr√°fico de dispersi√≥n l√©xica interactivo que muestre la distribuci√≥n de estos t√©rminos en el texto empleando la funci√≥n plotSpike.\nCreamos un nuevo diccionario con tres categor√≠as anal√≠ticas del espacio: social, religioso y dom√©stico. El primer tipo re√∫ne aquellos lugares de encuentro y diversi√≥n, como casinos, teatros y salones donde se da la interacci√≥n de los personajes nobles y de alta sociedad.\nEl segundo se encuentra representado por los lugares de culto, como catedrales y capillas. Son parte de los dominios de Ferm√≠n de Pas y su importancia en la trama viene de la fe que confesa Ana y su relaci√≥n con el misticismo.\nEl tercero congrega el ambiente dom√©stico de car√°cter √≠ntimo. Son lugares de vida cotidiana, como la casa, las habitaciones, la alcoba y las cocinas. Muchas de las escenas de la novela transcurren en estos espacios, donde se reflejan las angustias de Ana, como la expresi√≥n y transgresi√≥n de la intimidad del hogar.\n\n\nC√≥digo\n# Crea un diccionario solo sobre espacio,\n# con subcategor√≠as m√°s detalladas\ndicf &lt;- dictionary(\n  list(\n    social=c(\"casino\",\"teatro\",\"espol√≥n\",\n             \"Paseo de Verano\",\"Paseo de los curas\",\n             \"calle\",\"plaza\",\"tertulia\",\"salon\",\"vivero\"),\n    religioso=c(\"catedral\",\"capilla\",\"sacrist√≠a\",\n                \"claustro\",\"seminario\"),\n    dom√©stico=c(\"\\\\bcasa\\\\b\",\"hogar\",\"alcoba\",\n                \"habitaci√≥n\",\"cama\",\"cocina\",\"despensa\")))\n\n# Filtra las palabras clave empleando\n# el nuevo diccionario\nft &lt;- filterWords(cp, dicf)\n\n# A√±ade la palabra cap√≠tulo al n√∫mero\n# de los cap√≠tulos para facilitar la\n# lectura de los datos\nft$name &lt;- paste0(\"Cap√≠tulo \",ft$name)\n\n# Genera el gr√°fico de dispersi√≥n l√©xica\n# circular interactivo\nplotSpike(ft, \n          title = 'Los espacios de \"La Regenta\"', \n          subtitle = \"Gr√°fico de dispersi√≥n l√©xica para distintos tipos de espacio.\", \n          palette = pal$cat.brewer.Dark2.8[c(1:4)],\n          label.size = 3, \n          line.width = 0.3, \n          ring.col=\"black\")\n\n\n\n\n\n\n\nCada c√≠rculo representa un cap√≠tulo y el el n√∫mero que aparece en el centro es la cantidad total de t√©rminos encontrados seg√∫n el diccionario. Si pasamos el cursor sobre un ‚Äúpincho‚Äù que sale del c√≠rculo, se despliega el nombre del cap√≠tulo, la categor√≠a del diccionario a que pertenece la palabra, el total de palabras encontradas para esa categor√≠a y la palabra clave.\nAhora, los patrones quedan mucho m√°s evidentes. Los espacios religiosos se destacan en los dos primeros cap√≠tulos de forma clara, as√≠ como en el cap√≠tulo 23. Adem√°s, es ah√≠ donde termina la novela. Los ambientes dom√©sticos, predominantes en los pasajes dedicados a la interacci√≥n con Ana, que se alternan con los espacios ‚Äúsociales‚Äù en los que se desenvuelve la vida de la ciudad y de los dem√°s personajes.\n\n\nPeso de los temas\n¬øCu√°l la importancia de cada tema en la obra? Para responder a esta pregunta, podemos calcular la prevalencia de los temas en el texto. El peso de un tema se calcula de dos maneras:\n\npor la frecuencia absoluta - que consiste en solamente contar el n√∫mero de palabras clave asociadas a ese tema en el texto; o\npor la frecuencia relativa - obtenida dividiendo el n√∫mero de palabras clave asociadas a ese tema por el n√∫mero total de palabras en el texto. En ese sentido, representa una medida de densidad del tema.\n\nMientras que la frecuencia absoluta nos da una idea de la cantidad de veces que un tema es mencionado, la frecuencia relativa nos permite comparar la importancia de los temas en textos de diferente longitud.\n\n\nC√≥digo\n# La funci√≥n countKeywords\n# cuenta las palabras clave de un\n# diccionario en un texto\nxy &lt;- countKeywords(cp, \n                    dic, \n                    rel.freq = F, \n                    quietly = TRUE)\n\n# Elimina los t√©rminos no encontrados\nxy &lt;- xy[xy$frequency&gt;0,]\n\n# Elimina la variable de grupos\n# (no hay grupos en este caso)\nxy$groups &lt;- NULL\n\n# Muestra los resultados\nreactable(xy, resizable = TRUE)\n\n\n\n\n\n\n\nSi ordenamos los valores de la frecuencia del mayor al menor, vemos que el misticismo y el adulterio aparecen entre los m√°s frecuentes. El primero, por la presencia de Ferm√≠n de Pas y su relaci√≥n con Ana, y el segundo, por la trama principal de la novela. El espacio de la casa tambi√©n es relevante.\nSin embargo, la tabla no contiene informaci√≥n agregada por tema. Podr√≠amos utilizar una funci√≥n en R para agregar los resultados o emplear diferentes t√©cnicas de visualizaci√≥n para comparar los temas. En este caso, utilizaremos un gr√°fico de redes jer√°rquicas para visualizar la relaci√≥n entre los temas y su frecuencia en el texto.\n\n\nC√≥digo\n# Crea una red de temas con\n# los resultados obtenidos\nforceDirectedTree(xy,\n                  value_col = \"frequency\",\n                  max.radius = 60,\n                  height=500)\n\n\n\n\n\n\n\nVemos c√≠rculos de distintos tama√±os en el gr√°fico. Representan los grandes temas y su tama√±o indica su peso en la novela. Cada uno posee un conjunto de otros c√≠rculos m√°s peque√±os de mismo color que indican la importancia de cada palabra clave dentro del tema. As√≠ que el ‚ÄúMisticismo‚Äù, por ejemplo, aparece como el tema m√°s relevante y ‚ÄúMagistral‚Äù, ‚ÄúDi√≥s‚Äù y ‚ÄúFerm√≠n‚Äù como sus palabras clave centrales. La econom√≠a, por otra parte, parece no importar mucho en Vetusta.\nOtra manera de visualizar los mismos datos es a trav√©s de un treemap. En este caso, los temas se representan como rect√°ngulos de distintos tama√±os y colores, donde el tama√±o indica la importancia del tema y el color, su relaci√≥n con otros temas. El gr√°fico abajo es una versi√≥n modificada que emplea el algoritmo de Voronoi para distribuir las √°reas de forma precisa, pero con formas m√°s libres, incluso no rectangulares. Se llama Voronoi Tree.\n\n\nC√≥digo\n# Gr√°fico de Voronoi\nplotVoronoiTree(data = xy,\n                value_col = \"frequency\")\n\n\n\n\n\n\n\nLa diferencia central entre este √∫ltimo gr√°fico y el anterior se encuentra en el hecho de que la atenci√≥n est√° centrada en la contribuci√≥n de las palabras clave en la composici√≥n de cada tema. El la visualizaci√≥n anterior, el foco estaba en el peso relativo de los temas mucho m√°s que en sus componentes emp√≠ricos concretos.\n\n\nPersonajes en lugar de temas\n¬øQu√© tal si analizamos los personajes en lugar de los temas? ¬øC√≥mo se distribuyen en la novela? ¬øCu√°l es su importancia relativa? Para responder a estas preguntas, podemos emplear la misma l√≥gica de an√°lisis de temas, pero aplicada a los personajes.\nEn primer lugar, creamos un diccionario con los personajes de la novela a partir de la n√≥mina de personajes de la novela elaborada por Arg√ºeles (1984).\n\n\nC√≥digo\ndich &lt;- dictionary(\n  list(\n    hombres=\n      list(\n           √Ålvaro=c(\"√Ålvaro Mes√≠a\",\"√Ålvaro\",\"Mes√≠a\",\n                    \"presidente del casino\"),\n           Saturnino=c(\"Saturnino Berm√∫dez\",\"Saturnino\",\n                       \"Berm√∫dez\",\"Saturno\",\"Saturnillo\"),\n           Ferm√≠n=c(\"Magistral\",\"Provisor\",\"Ferm√≠n\",\n                    \"De Pas\",\"Ferm√≠n de Pas\",\"Magistral\"),\n           V√≠ctor=c(\"V√≠ctor\",\"V√≠ctor Quintanar\",\"Quintanar\"),\n           Otros=c(\n                   \"Agustinito\",\"Amadeo\",\"Anacleto\",\n                   \"Anselmo\",\"Antero\",\"Ant√≥n Ra√≠ces\",\n                   \"Antonio\",\"Barcaza\",\"Basilio\",\n                   \"Bautista\",\"Bedoya\",\"Belisario\",\n                    \"Ben√≠tez\",\"Bismark\",\"Campillo\",\n                   \"\\\\b[C]hato\\\\b\",\"don Carlos\",\n                   \"Pel√°ez\",\"Cayetano\",\n                   \"Cayetano Ripamil√°n\",\"Ripamil√°n\",\n                   \"Celedonio\",\"Col√°s\",\"marqu√©s de Corujedo\",\n                   \"Fr√≠gilis\",\"Crespo\",\"Custodio\",\n                   \"Ol√≠as de Cuervo\",\"se√±or Cuervo\",\n                   \"Diego\",\"Escosura\",\"\\\\b[E]studiante\\\\b\",\n                   \"Pepe\",\"Trabuco\",\"Foja\",\"Fortunato\",\n                   \"Francisco de As√≠s\",\"Francisco de Pas\",\n                   \"Francisco de Osuna\",\"Francisco P√°ez\", \n                   \"se√±or P√°ez\", \"se√±or de P√°ez\",\n                   \"Francisco Carraspique\",\"Froil√°n\",\n                   \"don Frutos\",\"Frutos Redondo\",\"Fulgosio\",\n                   \"Germ√°n\",\"Glocester\",\"Restituto\",\n                   \"se√±or Infanz√≥n\", \"el Infanz√≥n\",\n                   \"Iriarte\",\"Joaquinito\",\"Juanito\",\n                   \"Leando\",\"Maroto\",\"marqu√©s de Vegallana\",\n                   \"\\\\s{1}[M]arqu√©s\\\\b\",\"Mart√≠nez\",\n                   \"Mat√≠as\",\"Matiella\",\"monaguillo\",\n                   \"se√±or Orgaz\",\"\\\\b[P]alma\\\\b\",\n                   \"Paco\",\"Paquito\",\"Palomo\",\n                   \"Rodr√≠guez\",\"Parcerisa\",\"Pedro\",\n                   \"\\\\b[P]erales\\\\b\",\"Pin√≥n\",\n                   \"Pompeyo\",\"Pompeyo Guimar√°n\",\"Guimar√°n\",\n                   \"Robustiano\",\"se√±or Roque\",\n                   \"Rosendo\",\"don Santos\",\"Sousa\",\n                   \"Trif√≥n\",\"\\\\b[V]inagre\\\\b\",\n                   \"Vinculete\")\n           ),\n    mujeres=\n      list(\n        Ana=c(\"Ana\",\"Anita\",\"Regenta\"),\n        Obdulia=c(\"Obdulia\",\"Obdulia Fandi√±o\",\n                  \"Fandi√±o\",\"Obdulita\"),\n        Otras=c(\n                \"Agapita\",\"√Ågueda\",\"Angelina\",\n                \"Anuncita\",\"do√±a Anuncia\",\"Camila\",\n                \"Carolina\",\"Se√±ora de Infanz√≥n\", \"la Infanz√≥n\",\n                \"Celestina\",\"Edelmira\",\"Emma\",\n                \"Fabiolita\",\"Fulgencia\",\"Gertrudis\",\n                \"la Gonz√°lez\",\"Juana\",\"Lola\",\n                \"do√±a Luc√≠a\",\"marquesa\",\"Rufina\",\n                \"Olvido\",\"do√±a Paula\",\"Pepa\",\n                \"Guimar√°n, Perp√©tua\",\"\\\\b[P]ilar\\\\b\",\n                \"Petra\",\"do√±a Petronila\",\"Ramona\",\n                \"\\\\bRita\\\\b\",\"\\\\bRosa\\\\b\",\"Rosita\",\n                \"Rudesinda\",\"Servanda\",\"T√°rsila\",\n                \"\\\\b[T]eresa\\\\b\",\"Teresina\",\n                \"√örsula\",\"Visitaci√≥n\",\"\\\\b[V]isita\\\\b\",\n                \"viuda del marqu√©s de Corujedo\")\n        )\n  )\n)\n\n\n\nComo se puede observar, se tratan de muchos personajes, algunos de ellos con varios nombres o formas de denominaci√≥n. Una vez que ya tenemos el diccionario en manos, podemos proceder a contar la frecuencia de aparici√≥n de los personajes en la novela.\nPara a√±adir emoci√≥n al asunto, vamos a hacerlo por cap√≠tulo. De esa manera, seremos capaces de acompa√±ar la evoluci√≥n de los personajes a lo largo de la novela, su participaci√≥n en cada etapa y su rol en la estructura.\n\n\nC√≥digo\n# cuenta la frecuencia de los personajes\n# en la novela por cap√≠tulo\nxp &lt;- countKeywords(cp, \n                    dich, \n                    rel.freq = F, \n                    group.var = \"capitulo\",\n                    quietly = TRUE)\n\n# Agrega los resultados por los dos niveles\n# de c√≥digo del diccionario\nxx &lt;- aggregate(list(frequency=xp$frequency), \n                by=list(groups=xp$groups, \n                        level1=xp$level2), \n                sum, na.rm=T)\n\n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Ordena por cap√≠tulo\nxx &lt;- xx[order(xx$groups),]\n\n# Muestra los resultados\nreactable(xx, resizable=TRUE)\n\n\n\n\n\n\n\nPodemos ver c√≥mo Ana ni siempre es la que m√°s aparece asociada a otros en la novela. En algunos cap√≠tulos Ferm√≠n o √Ålvaro toman la delantera, mientras que en otros pasajes el protagonismo es m√°s coral, con varios personajes siendo mencionados simult√°neamente.\nComo en el ejemplo anterior, tambi√©n podemos emplear t√©cnicas de visualizaci√≥n de datos para representar la informaci√≥n de manera m√°s clara y atractiva. No obstante, ahora disponemos de una informaci√≥n adicional -el cap√≠tulo-, de modo que la informaci√≥n est√° m√°s detallada y requiere otros enfoques para su representaci√≥n gr√°fica.\nUna primera alternativa consiste en emplear un diagrama de Sankey, que nos permitir√° visualizar la relaci√≥n entre los personajes y los cap√≠tulos. Se trata de un diagrama de flujo en el que los nodos representan las entidades y las conexiones entre ellos las relaciones. En este caso, los nodos ser√°n los personajes y los cap√≠tulos, y las conexiones las apariciones de los personajes en los cap√≠tulos.\nLa funci√≥n plotSankey de tenet nos permite hacerlo de manera sencilla. solo tenemos que indicarle los datos, el nodo de origen (‚Äúfrom=‚Äù), el nodo de destino (‚Äúto=‚Äù) y el valor (‚Äúvalue=‚Äù) que queremos representar.\n\n\nC√≥digo\nplotSankey(xx, \n           from = \"level1\", \n           to=\"groups\", \n           value = \"frequency\", \n           opacity = 0.05)\n\n\n\n\n\n\n\nLos resultados son reveladores. Aunque Ana es el personaje que m√°s aparece en la novela, su presencia no es constante a lo largo de los cap√≠tulos. En algunos de ellos, como el 8 o el 22, aparece de modo t√≠mido. Esta tendencia resulta a√∫n m√°s acentuada en el caso de los dem√°s personajes.\nAunque el diagrama de Sankey es una buena opci√≥n, posee una limitaci√≥n clara: solo permite visualizar los datos de un personaje o un cap√≠tulo a la vez. Para superar dicha restricci√≥n, podemos emplear un diagrama de flujo (streamgraph) que nos permita visualizar la evoluci√≥n de todos los personajes a lo largo de los cap√≠tulos.\nLo haremos con la funci√≥n plotStream de tenet. Al igual que en el caso anterior, solo tenemos que indicarle los datos, el nodo de origen (‚Äúx=‚Äù), el nodo de destino (‚Äúy=‚Äù) y el grupo (‚Äúgroup=‚Äù). Tambi√©n podemos elegir la paleta de colores que queremos emplear (‚Äúpalette=‚Äù).\n\n\nC√≥digo\nplotStream(xx, \n           x=\"groups\",\n           y=\"frequency\", \n           group=\"level1\",\n           palette=pal$cat.ggsci.simpsons.16)\n\n\n\n\n\n\n\nEn este √∫ltimo gr√°fico queda m√°s clara la evoluci√≥n de los personajes en la novela y los momentos en los que el autor decide vincularles m√°s o menos en su narrativa. Adem√°s, al pasar el cursor sobre un cap√≠tulo, podemos ver la frecuencia de aparici√≥n de todos y cada uno de los personajes en ese cap√≠tulo en concreto.\nOtra manera de verlo es por medio de un gr√°fico de s√≠mbolos proporcionales organizados en una grada de N personajes por N cap√≠tulos. En este caso, la funci√≥n plotGrid del paquete tenet nos permite hacerlo de manera sencilla:\n\n\nC√≥digo\nplotGrid(xx, \n         x=\"groups\", \n         y=\"level1\", \n         size=\"frequency\", \n         color=\"level1\", \n         width_svg = 9, height_svg = 4, \n         leg.size=\"Frecuencia\", \n         leg.color=\"Personaje\",  \n         grid.color=\"grey99\")\n\n\n\n\n\n\nTambi√©n podemos estandarizar la frecuencia como porcentaje de la media. De ese modo, observamos la variaci√≥n de la cantidad de apariciones de los personajes en cada cap√≠tulo respecto a su media en la novela. Para ello, empleamos el par√°metro standardize de plotGrid. Tambi√©n podemos resaltar los valores m√°s altos haciendo con que los colores sean m√°s transparentes para los valores m√°s bajos. Para ello, empleamos el par√°metro alpha de plotGrid.\n\n\nC√≥digo\nplotGrid(xx, \n         x=\"groups\", \n         y=\"level1\", \n         size=\"frequency\", \n         color=\"level1\", \n         width_svg = 9, height_svg = 4, \n         leg.size=\"Media (%)\", # Cambia la leyenda \n         leg.color=\"Personaje\",  \n         grid.color=\"grey99\",\n         standardize = TRUE,   # Estandariza los valdores\n         alpha=TRUE)           # Transparencia\n\n\n\n\n\n\nLa comparaci√≥n entre los dos √∫ltimos gr√°ficos nos brinca entradas distintas a la novela. En el primero, queda evidente la diferencia entre personajes con una participaci√≥n m√°s o menos constante en los cap√≠tulos y otros que aparecen de manera m√°s ocasional o intermitente. El segundo, por otro lado, no solo se√±ala los puntos donde cada personaje aparece m√°s o menos de forma muy clara, sino que tambi√©n permite comparar los cap√≠tulos entre s√≠. Dos ejemplos extremos: el cap√≠tulo 3 (introducci√≥n de Ana en la novela), en el que solamente V√≠ctor aparece m√°s de lo habitual, y el cap√≠tulo 13 (la comida en la casa de los Marqueses de Vegallana), que se puede considerar coral por la diversidad de personajes que entran en escena. Un frenes√≠ en el que todos los grupos superan la media de frecuencia de los dem√°s cap√≠tulos de la novela.\n\n\nAsociaci√≥n entre temas (y personajes)\nHasta ahora hemos analizado la frecuencia de aparici√≥n de los personajes en la novela y c√≥mo esta var√≠a a lo largo de los cap√≠tulos. No obstante, tambi√©n podemos estudiar la relaci√≥n que los temas desarrollan entre s√≠. ¬øHasta qu√© punto dos ideas o conceptos aparecen en el mismo p√°rrafo o cap√≠tulo del libro? Por ejemplo, ¬øcu√°l es la relaci√≥n entre iglesia y misticismo o entre sentimientos y el tiempo?\nPara responder a estas preguntas, vamos a emplear la funci√≥n matchCodes de tenet. Esta funci√≥n nos permite calcular la frecuencia en la que dos c√≥digos del mismo diccionario aparecen juntos en cada frase, p√°rrafo, cap√≠tulo o otra unidad de agregaci√≥n del corpus.\n\n\nC√≥digo\n# Reorganiza el corpus seg√∫n\n# sentencias o frases\ncs &lt;- corpus_reshape(cp, \"sentences\")\n\n# Calcula la frecuencia en la\n# que dos codigos del mismo \n# diccionario aparecen juntos\n# en cada frase\nd1 &lt;- matchCodes(cs, \n                dic, \n                level = 1, \n                quietly=TRUE)\n\n# Ordena los resultados de mayor a menor\nd1 &lt;- d1[order(d1$value, decreasing = T),]\n\n# Muestra los resultados\nplotChord(d1, \n          from = \"term1\", \n          to =\"term2\", \n          value= \"value\")\n\n\n\n\n\n\n\nComo vemos, los conceptos se encuentran muy relacionados entre s√≠. No resulta nada sorprendente que haya una alta frecuencia de aparici√≥n de ‚Äúmisticismo‚Äù en las mismas frases en las que aparece ‚Äúiglesia‚Äù o ‚Äúreligi√≥n‚Äù. De igual modo, la relaci√≥n entre ‚Äúsentimientos‚Äù y ‚Äútiempo‚Äù es muy estrecha, lo que sugiere que el autor emplea el tiempo como un recurso narrativo para expresar los sentimientos de los personajes. La sociedad, curiosamente, parece tener la misma predilecci√≥n por el ‚Äúmisticismo‚Äù y el ‚Äúadulterio‚Äù.\nEsta estrategia se puede hacer m√°s compleja si se emplean m√°s categor√≠as o si combinamos personajes y temas en un mismo diccionario. Cabe a cada uno determinar cu√°l es la perspectiva que resulta m√°s fruct√≠fera para llevar a cabo el an√°lisis. Las posibilidades son muy amplias y permiten una gran maleabilidad.\nPodemos repetir el mismo an√°lisis con los personajes. ¬øQu√© personajes se relacionan m√°s entre s√≠? ¬øCu√°les son los personajes que presentan m√°s v√≠nculos con los dem√°s? ¬øExiste alg√∫n tipo de liderazgo o influencia entre ellos? Volvemos a aplicar el mismo m√©todo, pero ahora con un diccionario de personajes m√°s detallado, sin agregar en una categor√≠a ‚Äúotros y otras‚Äù.\nEl primer paso consiste en crear un diccionario con todos los personajes sin agregar.\n\n\nC√≥digo\n# diccionario de personajes\n# sin agregar en una categor√≠a\n# otros y otras\ndic.per &lt;- dictionary(\n  list(\n    hombres=\n      list(\n        √Ålvaro=c(\"√Ålvaro Mes√≠a\",\n                 \"√Ålvaro\",\n                 \"Mes√≠a\",\n                 \"presidente del casino\"),\n        Saturnino=c(\"Saturnino Berm√∫dez\",\n                    \"Saturnino\",\n                    \"Berm√∫dez\",\n                    \"Saturno\",\n                    \"Saturnillo\"),\n        Ferm√≠n=c(\"Magistral\",\n                 \"Provisor\",\n                 \"Ferm√≠n\",\n                 \"De Pas\",\n                 \"Ferm√≠n de Pas\",\n                 \"Magistral\"),\n        V√≠ctor=c(\"V√≠ctor\",\n                 \"V√≠ctor Quintanar\",\n                 \"Quintanar\"),\n        Agustinito=\"Agustinito\",\n        Amadeo=\"Amadeo\",\n        Anacleto=\"Anacleto\",\n        Anselmo=\"Anselmo\",\n        Antero=\"Antero\",\n        Ant√≥n=\"Ant√≥n Ra√≠ces\",\n        Antonio=\"Antonio\",\n        Barcaza=\"Barcaza\",\n        Basilio=\"Basilio\",\n        Bautista=\"Bautista\",\n        Bedoya=\"Bedoya\",\n        Belisario=\"Belisario\",\n        Ben√≠tez=\"Ben√≠tez\",\n        Bismark=\"Bismark\",\n        Campillo=c(\"Campillo\",\"\\\\b[C]hato\\\\b\"),\n        Carlos=\"Carlos\",\n        Pelaez=\"Pel√°ez\",\n        Ripamilan=c(\"Cayetano\",\n                    \"Cayetano Ripamil√°n\",\n                    \"Ripamil√°n\"),\n        Celedonio=\"Celedonio\",\n        Col√°s=\"Col√°s\",\n        Corujedo=\"marqu√©s de Corujedo\",\n        Fr√≠gilis=c(\"Fr√≠gilis\",\"Crespo\"),\n        Custodio=c(\"Custodio\"),\n        Cuervo=c(\"Ol√≠as de Cuervo\",\"se√±or Cuervo\"),\n        Diego=\"Diego\",\n        Escosura=\"Escosura\",\n        Estudiante=c(\"\\\\b[E]studiante\\\\b\",\"Pepe\",\"Trabuco\"),\n        Foja=\"Foja\",\n        Fortunato=\"Fortunato\",\n        \"Francisco de As√≠s\"=\"Francisco de As√≠s\",\n        \"Francisco de Pas\"=\"Francisco de Pas\",\n        \"Francisco de Osuma\"=\"Francisco de Osuna\",\n        P√°ez=c(\"Francisco P√°ez\", \"se√±or P√°ez\", \"se√±or de P√°ez\"),\n        \"Francisco Carraspique\"=\"Francisco Carraspique\",\n        Froil√°n=\"Froil√°n\",\n        Frutos=c(\"don Frutos\",\"Frutos Redondo\"),\n        Fulgosio=\"Fulgosio\",\n        Germ√°n=\"Germ√°n\",\n        Glocester=c(\"Glocester\",\"Restituto\"),\n        Infanz√≥n=c(\"se√±or Infanz√≥n\", \"el Infanz√≥n\"),\n        Iriarte=\"Iriarte\",\n        Joaquinito=\"Joaquinito\",\n        Juanito=\"Juanito\",\n        Leandro=\"Leando\",\n        Maroto=\"Maroto\",\n        Vegallana=c(\"marqu√©s de Vegallana\",\"\\\\s{1}[M]arqu√©s\\\\b\"),\n        Mart√≠nez=\"Mart√≠nez\",\n        Mat√≠as=\"Mat√≠as\",\n        Matiella=\"Matiella\",\n        monaguillo=\"monaguillo\",\n        \"se√±or Orgaz\"=\"se√±or Orgaz\",\n        Palma=\"\\\\b[P]alma\\\\b\",\n        Paquito=c(\"Paco\",\"Paquito\"),\n        Palomo=c(\"Palomo\",\"Rodr√≠guez\"),\n        Parcerisa=\"Parcerisa\",\n        Pedro=\"Pedro\",\n        Perales=\"\\\\b[P]erales\\\\b\",\n        Pin√≥n=\"Pin√≥n\",\n        Pompeyo=c(\"Pompeyo\",\"Pompeyo Guimar√°n\",\"Guimar√°n\"),\n        Robustiano=\"Robustiano\",\n        Roque=\"se√±or Roque\",\n        Rosendo=\"Rosendo\",\n        Santos=\"don Santos\",\n        Sousa=\"Sousa\",\n        Trif√≥n=\"Trif√≥n\",\n        Vinagre=\"\\\\b[V]inagre\\\\b\",\n        Vinculete=\"Vinculete\"\n        ),\n    mujeres=\n      list(\n        Ana=c(\"Ana\",\n              \"Anita\",\n              \"Regenta\"),\n        Obdulia=c(\"Obdulia\",\n                  \"Obdulia Fandi√±o\",\n                  \"Fandi√±o\",\n                  \"Obdulita\"),\n        Agapita=\"Agapita\",\n        √Ågueda=\"√Ågueda\",\n        Angelina=\"Angelina\",\n        Anunciaci√≥n=c(\"Anuncita\",\"do√±a Anuncia\"),\n        Camila=\"Camila\",\n        Carolina=c(\"Carolina\",\"Se√±ora de Infanz√≥n\", \"la Infanz√≥n\"),\n        Celestina=\"Celestina\",\n        Edelmira=\"Edelmira\",\n        Emma=\"Emma\",\n        Fabiolita=\"Fabiolita\",\n        Fulgencia=\"Fulgencia\",\n        Gertrudis=\"Gertrudis\",\n        \"La Gonz√°lez\"=\"la Gonz√°lez\",\n        Juana=\"Juana\",\n        Lola=\"Lola\",\n        Luc√≠a=\"do√±a Luc√≠a\",\n        Marquesa=c(\"marquesa\",\"Rufina\"),\n        Olvido=\"Olvido\",\n        Paula=\"do√±a Paula\",\n        Pepa=\"Pepa\",\n        Perp√©tua=\"Guimar√°n, Perp√©tua\",\n        Pilar=\"\\\\b[P]ilar\\\\b\",\n        Petra=\"Petra\",\n        Petrolina=\"do√±a Petronila\",\n        Ramona=\"Ramona\",\n        Rita=\"\\\\bRita\\\\b\",\n        Rosa=\"\\\\bRosa\\\\b\",\n        Rosita=\"Rosita\",\n        Rudesinda=\"Rudesinda\",\n        Servanda=\"Servanda\",\n        T√°rsila=\"T√°rsila\",\n        Teresa=\"\\\\b[T]eresa\\\\b\",\n        Teresina=\"Teresina\",\n        √örsula=\"√örsula\",\n        Visita=c(\"Visitaci√≥n\",\"\\\\b[V]isita\\\\b\"),\n        \"Viuda de Corujedo\"=\"viuda del marqu√©s de Corujedo\"\n        )\n  )\n)\n\n\n\nUna vez que se ha definido el diccionario, se procede a cargar el corpus y a calcular las asociaciones entre los c√≥digos del diccionario. Para ello, se emplea la funci√≥n matchCodes() del paquete tenet. Esta funci√≥n calcula la frecuencia en la que dos c√≥digos del mismo diccionario aparecen juntos en cada p√°rrafo.\nPara facilitar el an√°lisis de asociaciones entre personajes, hemos decidido eliminar las asociaciones con el c√≥digo Ana. Resulta obvio que La Regenta es el personaje principal de la novela y, por tanto, aparecer√° en la mayor√≠a de los p√°rrafos. Al eliminar esta constante, nuevos patrones emergen y posibilitan enriquecer el an√°lisis. A continuaci√≥n, se presenta el c√≥digo que permite realizar este c√°lculo:\n\n\nC√≥digo\n# Emplea el corpus organizado\n# seg√∫n p√°rrafos\ncpp &lt;- corpus(regp, \n              text_field = \"texto\")\n\n# Calcula la frecuencia en la\n# que dos c√≥digos del mismo \n# diccionario aparecen juntos\n# en cada p√°rrafo\nd1 &lt;- matchCodes(cpp, \n                 dic.per, \n                 level = 2, \n                 quietly=TRUE)\n\n# Ordena los resultados de mayor a menor\nd1 &lt;- d1[order(d1$value, decreasing = T),]\n\n# Elimina las asociaciones con Ana\nd1 &lt;- d1[d1$term1!=\"Ana\",]\nd1 &lt;- d1[d1$term2!=\"Ana\",]\n\n# Genera un gr√°fico de cuerdas\n# para visualizar las asociaciones\nplotChord(d1, \n          from = \"term1\", \n          to =\"term2\", \n          value= \"value\", \n          elementId = \"chord3\")\n\n\n\n\n\n\n\nEl gr√°fico de cuerdas muestra la centralidad de Ferm√≠n y √Ålvaro, que presentan v√≠nculos con un abanico amplio de personajes. Los dem√°s, se enmarcan en relaciones m√°s espec√≠ficas y limitadas. Petra, por ejemplo, act√∫a como intermediaria entre Ana y sus admiradores y esta ‚Äúfunci√≥n‚Äù queda patente en sus conexiones con Ferm√≠n, √Ålvaro y V√≠ctor (que en ese caso es su patr√≥n).\nAdem√°s, la importancia de los personajes puede variar seg√∫n cada cap√≠tulo. Por ejemplo, en el cap√≠tulo 4, donde se describe la infancia de Ana, aparecen personajes como Camila, Carlos y Germ√°n, que, luego, apenas vuelven a ser mencionados. Por eso, ser√≠a interesante analizar c√≥mo la red de asociaci√≥n entre personajes var√≠a seg√∫n el cap√≠tulo.\nEl siguiente c√≥digo genera una visualizaci√≥n de red para cada cap√≠tulo que muestra la frecuencia en que los personajes aparecen juntos en los mismos p√°rrafos. Hemos elegido eliminar a Ana por dos motivos. Primero, para facilitar la visualizaci√≥n, puesto que se trata del personaje principal y que aparece relacionada a casi todos los dem√°s. Segundo, y m√°s importante, su ausencia nos permite observar las relaciones entre los dem√°s personajes, que de otro modo quedar√≠an opacadas por la presencia de Ana. Por ejemplo, de ese modo podemos ver mejor cu√°ndo Ferm√≠n y √Ålvaro toman el centro de la narraci√≥n o cuando otros personajes interesantes, como la marquesa, se destacan.\n\n\nC√≥digo\n# Carga los paquetes necesarios\nlibrary(network)\nlibrary(sna)\nlibrary(ggnetwork)\nlibrary(ggplot2)\n\n# Crea una lista para guardar\n# los gr√°ficos de red\n# de cada cap√≠tulo\npx &lt;- list()\n\n# Para cada cap√≠tulo\nfor(i in 1:30){\n\n  # Extrae el texto del cap√≠tulo\n  c1 &lt;- cp[i]\n  \n  # Reorganiza en p√°rrafos\n  c1 &lt;- corpus_reshape(c1, to=\"paragraphs\")\n  \n  # Calcula la frecuencia de los\n  # personajes\n  d1 &lt;- matchCodes(c1, \n                   dic.per, \n                   level = 2, \n                   quietly=TRUE)\n  \n  # Elimina a Ana para facilitar\n  # la visualizaci√≥n\n  d1 &lt;- d1[d1$term1!=\"Ana\",]\n  d1 &lt;- d1[d1$term2!=\"Ana\",]\n\n  # Ordena los resultados\n  d1 &lt;- d1[order(d1$value, decreasing = T),]\n\n  # Crea una red\n  n1 &lt;- network(d1, \n                directed = F)\n  \n  # Convierte en un layout\n  # de red para la visualizaci√≥n\n  gn &lt;- ggnetwork(n1, \n                  layout = \"kamadakawai\", \n                  cell.jitter = 0.75)\n\n  # Genera el gr√°fico\n  p &lt;- ggplot(gn, \n              aes(x = x, \n                  y = y, \n                  xend = xend, \n                  yend = yend)) +\n          geom_edges(\n                color = \"grey90\",\n                aes(size=value), \n                curvature=0.25) +\n        geom_edges(\n                size=0.1, \n                curvature=0.25, \n                color=\"purple\") +\n          geom_nodetext(\n                aes(label = vertex.names),\n                fontface = \"bold\")+\n          theme_blank()+\n          labs(title=paste0(\"**Cap√≠tulo \",i,\"**\"))+\n          theme(plot.title = \n                  ggtext::element_markdown(\n                          size=15, \n                          color=\"darkgreen\"), \n                legend.position = \"none\",\n                plot.margin=grid::unit(\n                  c(0.75,0.75,0.75,0.75), \n                  \"cm\"))\n\n  # Almacena el gr√°fico en\n  # la lista\n  px[[i]] &lt;- p\n\n}\n\n# Carga el paquete que\n# permitir√° visualizar\n# las 30 redes en un\n# solo gr√°fico\nlibrary(egg)\n\n# Organiza los gr√°ficos\n# en tres columnas y diez\n# filas\nggarrange(plots=px, \n          ncol=3, \n          nrow=10)\n\n\n\n\n\n\n\n\n\nLa figura nos muestra que cada cap√≠tulo presenta un patr√≥n distinto de interacci√≥n entre los personajes. La complejidad de las redes tambi√©n var√≠a de modo considerable. En algunos casos, como los cap√≠tulos 4 y 7, la red es muy simple, con pocos personajes y pocas conexiones. En otros, como el cap√≠tulo 13, la red es mucho m√°s densa y compleja. En general, Ferm√≠n y √Ålvaro son los personajes m√°s centrales, pero no siempre. En algunos cap√≠tulos, otros personajes, como la marquesa, toman el centro de la narraci√≥n.",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "regenta.html#clusters-y-escalonado-de-textos",
    "href": "regenta.html#clusters-y-escalonado-de-textos",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "Clusters y escalonado de textos",
    "text": "Clusters y escalonado de textos\n\nAn√°lisis de conglomerados (clusters)\nEl an√°lisis de conglomerados es una t√©cnica que permite agrupar textos en funci√≥n de su similitud. En el ejemplo abajo, se utiliza un algoritmo de agrupamiento jer√°rquico para agrupar los cap√≠tulos de la novela en funci√≥n de la similitud de sus palabras. La similitud se mide a partir de la distancia euclidiana entre ellos.\n\n\nC√≥digo\n# Crea los tokens\ntk &lt;- tokens(cp, \n             remove_punct = T, \n             remove_numbers = T, \n             remove_separators = T, \n             remove_symbols = T)\n\n# Remueve las palabras vac√≠as\ntk &lt;- tokens_remove(tk, \n                    pattern=stopwords(\"es\"))\n\n# Crea la matriz de frecuencias\ndtm &lt;- dfm(tk)\n\n# Carga el paquete necesario\nlibrary(quanteda.textstats)\n\n# Calcula la distancia entre \n# los cap√≠tulos y los agrupa en\n# conglomerados\ntstat_dist &lt;- as.dist(textstat_dist(dtm))\nclust &lt;- hclust(tstat_dist)\n\n# Muestra los resultados\nplot(clust, xlab = \"Distance\", ylab = NULL)\n\n\n\n\n\n\n\n\n\n\nEl dendrograma representa una forma de representaci√≥n visual de las distancias entre los cap√≠tulos. Vemos existe un gran grupo de cap√≠tulos (con sus subgrupos) y dos conglomerados m√°s peque√±os. Uno, formado por los cap√≠tulos 12, 13, 16, 20, 21 y 22 y, otro, por el 29 y 30.\nComo podemos ver, la organizaci√≥n en grupos resulta coherente con el desarrollo tem√°tico de cada parte de la novela. Por ejemplo, los cap√≠tulos 4 y 5 cuentan la infancia y juventud de Ana. El 29 y el 30 son los que concluyen la obra con la consumaci√≥n del adulterio y su desenlace tr√°gico.\nLos apartados 12, 20 y 22, por otro lado, se centran en la relaci√≥n de Ferm√≠n con sus detractores y en la muerte de Don Santos. Los cap√≠tulos 13, 16 y 21, por otro lado, se centran en las tentaciones iniciales de Ana con Mes√≠a y en su entrega al misticismo intermediada por Ferm√≠n.\nEl 11 y el 15 se dedican a la relaci√≥n de Ferm√≠n con su madre.\nLos cap√≠tulos 1, 2, 3, 6, 7, 8,14 y 24, por otro lado, describen la presentaci√≥n de los personajes principales, vida social de Vetusta, el car√°cter de Ferm√≠n, as√≠ como las fiestas en el casino y en casa de los marqueses.\nFinalmente, el bloque representado por los apartados 9, 10, 17, 18, 19, 23, 25, 26, 27 y 28 se centra en los constantes titubeos de Ana entre el misticismo (representado por Ferm√≠n) y el romanticismo / erotismo (simbolizado por Mes√≠a).\n\n\nEscalonado unidimensional de textos: Wordfish\nEl escalonado de textos es una t√©cnica que permite visualizar la relaci√≥n entre textos en un espacio unidimensional. La t√©cnica empleada en este caso es el Wordfish (Slapin y Proksch 2008). Se trata de una t√©cnica de estimaci√≥n de puntos ideales a partir de modelos estad√≠sticos que parten de las frecuencias de las palabras. En este caso, hemos aplicado el escalonado de textos a los cap√≠tulos de La Regenta para ver c√≥mo se relacionan entre s√≠.\n\n\nC√≥digo\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(ggplot2)\n\nwf &lt;- textmodel_wordfish(dtm)\n\ntextplot_scale1d(wf) +\n  geom_hline(yintercept = 0, \n             linetype = \"dashed\",\n             color=\"red3\")\n\n\n\n\n\n\n\n\n\nEsta escala se podr√≠a interpretar de distintas maneras. Una de ellas es que los cap√≠tulos situados m√°s a la izquierda representan una mayor intensidad de la vida social de Vetusta, mientras que aquellos m√°s a la derecha se relacionan con la vida privada, √≠ntima y la infancia de La Regenta.\nTambi√©n podr√≠amos leer los resultados de acuerdo con el protagonismo o mayor centralidad de ciertos personajes seg√∫n el punto de la escala. M√°s a la izquierda predominan los Marqueses, √Ålvaro Mes√≠a (antes de su relaci√≥n con Ana Ozores) y la sociedad vetustense. En el centro se sit√∫a Ferm√≠n de Pas, que se interpone entre la vida privada de Ana y la vida en sociedad. En la derecha encontramos a V√≠ctor, su esposo, √Ålvaro (hechos consumados) y en el extremo, la familia de Ana, especialmente en su infancia.\nDe todas formas, ambas interpretaciones sugieren una dualidad entre la vida √≠ntima y relativamente reservada de Ana en contraste con la vida social y p√∫blica de Vetusta. Los dos mundos se tocan en ocasiones concretas por intermedio de algunos actores que transitan entre ellos, como Ferm√≠n de Pas o √Ålvaro Mes√≠a.\n\n\nAn√°lisis de correspondencia (CA)\nEl an√°lisis de correspondencia es una t√©cnica de reducci√≥n de dimensionalidad de bases de datos complejas. En nuestro caso, tenemos una matriz de frecuencia de palabras en la que cada palabra representa una dimensi√≥n. El an√°lisis de correspondencia permite reducir el n√∫mero de dimensiones para que permitan visualizar la relaci√≥n entre los textos. El objetivo consiste en situar a los cap√≠tulos en un espacio bidimensional que permita revelar caracter√≠sticas estructurales latentes en la obra.\n\n\nC√≥digo\n# Carga los paquetes\nlibrary(quanteda.textmodels)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# Ejecuta el an√°lisis de correspondencias\ncca &lt;- textmodel_ca(dtm)\n\n# Extrae las coordenadas de los cap√≠tulos\ndd &lt;- data.frame(cca$rowcoord)\ndd$name &lt;- as.character(rownames(dd))\ndd &lt;- dd[, c(\"name\", \"Dim1\", \"Dim2\")]\n\n# crea un gr√°fico de dispersi√≥n \n# para examinar los resultados\nggplot(dd, aes(x = Dim1, y = Dim2)) +\n  geom_point() +\n  geom_text_repel(aes(label = name)) +\n  theme_classic() +\n  theme(legend.position = \"none\")+\n  geom_hline(yintercept = 0, \n             color = \"red3\", \n             linetype = \"dashed\") +\n  geom_vline(xintercept = 0, \n             color = \"red3\", \n             linetype = \"dashed\")+\n  xlab(\"Dimensi√≥n 1\") +\n  ylab(\"Dimensi√≥n 2\") +\n  labs(title = \"An√°lisis de correspondencias\")\n\n\n\n\n\n\n\n\n\nEl gr√°fico de dispersi√≥n muestra la relaci√≥n entre los cap√≠tulos de La Regenta en un espacio bidimensional. Los cap√≠tulos se sit√∫an en funci√≥n de su relaci√≥n sem√°ntica. Los cap√≠tulos m√°s cercanos entre s√≠ comparten un mayor n√∫mero de palabras y, por tanto, una mayor relaci√≥n sem√°ntica. Los cap√≠tulos m√°s alejados, por otro lado, comparten menos palabras y, por tanto, una menor relaci√≥n sem√°ntica.\nLa distancia al punto de origen (0,0) indica el peso del cap√≠tulo en cada una de las dimensiones. Por ejemplo, el cap√≠tulo 1 tiene un importante peso en ambos ejes, as√≠ como el 06. No obstante, el 22 y el 05 se destacan en la segunda dimensi√≥n, pero con poca incidencia sobre la primera.\nEn los resultados, llama la atenci√≥n el conglomerado de cap√≠tulos que se concentran en la parte derecha del gr√°fico. En su mayor√≠a, se ubican en la segunda parte de la novela, donde se narra la evoluci√≥n de la relaci√≥n entre Ana y Mes√≠a, as√≠ como el desenlace tr√°gico de la obra. Por otro lado, los cap√≠tulos perif√©ricos se relacionan con la vida social de Vetusta, los desarrollos espec√≠ficos de Ferm√≠n y la presentaci√≥n de los personajes.",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "regenta.html#footnotes",
    "href": "regenta.html#footnotes",
    "title": "La RegentaAn√°lisis de la novela en R",
    "section": "Notas",
    "text": "Notas\n\n\nNo nos detendremos aqu√≠ en explicar los detalles del c√°lculo de los indicadores. Cada t√©cnica suele estar asociada a un art√≠culo o referencia de ayuda que aclara el algoritmo. Para saber m√°s sobre la funci√≥n textstat_collocations, puedes consultar la ayuda en R ejecutando el comando help(textstat_collocations) de la consola de R.‚Ü©Ô∏é",
    "crumbs": [
      "La Regenta"
    ]
  },
  {
    "objectID": "sombreros.html",
    "href": "sombreros.html",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "",
    "text": "En este segundo documento, utilizaremos la obra de Miguel Mihura, Tres sombreros de copa, ilustrar un conjunto de t√©cnicas de an√°lisis textual distintas de los que hemos examinado con ‚ÄúLa Regenta‚Äù. Nuestro objetivo actual consiste en centrar la atenci√≥n en las redes de di√°logo y de palabras para identificar patrones y temas en la obra.",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "sombreros.html#introducci√≥n",
    "href": "sombreros.html#introducci√≥n",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "",
    "text": "En este segundo documento, utilizaremos la obra de Miguel Mihura, Tres sombreros de copa, ilustrar un conjunto de t√©cnicas de an√°lisis textual distintas de los que hemos examinado con ‚ÄúLa Regenta‚Äù. Nuestro objetivo actual consiste en centrar la atenci√≥n en las redes de di√°logo y de palabras para identificar patrones y temas en la obra.",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "sombreros.html#redes-de-di√°logo",
    "href": "sombreros.html#redes-de-di√°logo",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "Redes de di√°logo",
    "text": "Redes de di√°logo\nComo pod√©is ver en el apartado de preparaci√≥n, hemos estructurado el texto de la obra en una base de datos que contiene los di√°logos, el personaje que habla y el receptor del mensaje. A partir de dichas informaciones, podemos emplear t√©cnicas de an√°lisis de redes para identificar patrones de interacci√≥n entre los personajes.\nEl c√≥digo abajo transforma la base de datos en un objeto de red que puede ser visualizado. En este caso, utilizamos la funci√≥n simpleNetwork del paquete networkD3 para crear una visualizaci√≥n interactiva de la red de di√°logos entre los personajes de la obra.\n\n\nC√≥digo\n# carga los datos de la obra\nload(\"../textos/Tres_sombreros_de_copa.RData\")\n\n# Carga el paquete\nlibrary(igraph)\n\n# convierte en un objeto de red\ng &lt;- graph_from_data_frame(tsc_rd, \n                           directed = TRUE)\n\n# Define la frecuencia de interacci√≥n\n# como el peso del v√≠nculo entre\n# los dos personajes\nE(g)$weight &lt;- tsc_rd$freq\n\n\n# Crea la visualizaci√≥n de la red\nlibrary(networkD3)\n\nsimpleNetwork(tsc_rd, \n              fontSize = 14, \n              opacity=1)\n\n\n\n\n\n\nEl sociograma anterior representa de forma esquem√°tica los v√≠nculos entre los personajes. Podemos observar distintos patrones de conexi√≥n entre ellos. Algunos solo interact√∫an con otro, como ‚ÄúEl cazador astuto‚Äù. Otros se destacan por vincularse con muchos, como Fanny. Adem√°s, hay aquellos que conectan un grupo de personajes con otro, como Dionisio o Madame Olga. Cuando representamos las interacciones bajo una forma de red, salta a la vista la estructura de la obra. Emergen grupos muy densos, como el representado por Dionisio, Paula, Buby y Fanny, y otros perif√©ricos, como las tres muchachasm el cazador astuto y el anciano militar.\n\nProtagonismo como atributo de la red\nSi os pregunto, ¬øcu√°l es el personaje m√°s importante en la obra? ¬øQu√© responder√≠ais? Si conoc√©is bien la obra seguramente elegir√≠ais entre Dionisio y Paula. No obstante, ¬øc√≥mo podemos medir el protagonismo de un personaje? Adem√°s, ¬øa qu√© tipo de protagonismo nos referimos? ¬øAl n√∫mero de palabras que pronuncia? ¬øA la cantidad de personajes con los que interact√∫a? ¬øA la cantidad de veces que es mencionado por otros personajes?\nEn la teor√≠a de redes, el protagonismo de un nodo puede medirse a trav√©s de distintas m√©tricas de centralidad (Wasserman y Faust 1994). Dichas t√©cnicas permiten evaluar diferentes formas de influencia que cada personaje ejerce en la red. Por ejemplo, si miramos solo el n√∫mero de personajes con quien habla cada uno, podr√≠amos decir que Fanny es la m√°s importante. No obstante, si ponderamos todas las formas posibles de interacci√≥n, queda clara la centralidad de Dionisio en la obra. El esquema abajo muestra la anatom√≠a de una red social y los elementos estructurales que determinan las m√©tricas de centralidad m√°s comunes.\n\n\nAqu√≠ nos concentraremos en siete m√©tricas de centralidad que nos permiten evaluar el protagonismo de los personajes en la red de di√°logo. Estas son:\n\nDegree: mide el n√∫mero de conexiones que tiene un nodo con otros nodos. Fanny aqu√≠ es la reina, puesto que interact√∫a con ocho personajes distintos.\nCloseness: mide la distancia promedio de un nodo a todos los dem√°s nodos.\nBetweenness: mide la cantidad de veces que un nodo act√∫a como intermediario en la red. Dionisio, Fanny y Madame Olga son ejemplos en este sentido.\nEigenvector: mide la importancia de un nodo en funci√≥n de la importancia de sus vecinos. Si un personaje interact√∫a con otro que tambi√©n es importante, su importancia aumenta. Por ejemplo, el grupo formado por Dionisio, Paula, Buby, Fanny y ‚ÄúEl odioso se√±or‚Äù revela personajes con un alto valor en esa medida.\nPageRank: se trata de una medida basada en la anterior, pero que considera qui√©n se dirige a qui√©n. Por ejemplo, si una persona sigue a Taylor Swift en Twitter, no significa nada para su visibilidad en las redes. No obstante, si la cantante decide seguir a esta persona, su peso se ver√° aumentado de forma clara.\nHub: mide la cantidad de conexiones que tiene un nodo con otros nodos importantes.\nAuthority: mide la cantidad de conexiones recibidas de otros nodos de tipo hub en la red. Una persona que se dirije a otros nodos influyentes posee un enorme potencial de difusi√≥n de su mensaje.\n\nEn el c√≥digo abajo, visualizamos la posici√≥n de cada uno de los personajes de la obra seg√∫n las distintas m√©tricas mencionadas:\n\n\nC√≥digo\n# Carga el paquete tenet\nlibrary(tenet)\n\n# Genera el gr√°fico de centralidad\nplotNetCentrality(g)\n\n\n\n\n\n\n\n\n\nComo podemos observar, se confirma el protagonismo de Dionisio y Paula. No obstante, otros personajes tambi√©n se destacan en distintas m√©tricas. Por ejemplo, Fanny es la que m√°s conexiones tiene y act√∫a como intermediaria. Como hemos visto, ‚ÄúEl odioso se√±or‚Äù por su posici√≥n en la red y el contacto con otros persojanes de destaque, se sit√∫a bien en m√©tricas como autoridad, eigenvector y closeness.\n\n\nComunidades de personajes\nLa estructura de interacci√≥n de los personajes tambi√©n permite la identificar de m√≥dulos o grupos de personaje que presentan una mayor densidad de interacciones entre s√≠ que con el resto de la red. En la teor√≠a de redes, estos grupos se conocen como comunidades. En el c√≥digo abajo, identificamos las comunidades de personajes en Tres sombreros de copa:\n\n\nC√≥digo\n# Identifica las comunidades\nwb &lt;- cluster_walktrap(g)\n\n# Atribuye la membres√≠a \n# a los personajes\nV(g)$membership &lt;- wb$membership\n\n\n# Prepara la visualizaci√≥n\ndd &lt;- igraph_to_networkD3(g, \n                          group = V(g)$membership)\n\n# Crea la visualizaci√≥n\nforceNetwork(Links = dd$links,\n             Nodes = dd$nodes, \n             Source = 'source', \n             Target = 'target', \n             NodeID = 'name', \n             Group = 'group',\n             fontSize = 18,\n             opacity=1, \n             opacityNoHover = 0.25, \n             bounded = T)\n\n\n\n\n\n\nCada comunidad se representa por un color distinto. El algoritmo ha identificado ocho comunidades distintas. La primera conformada por Dionisio, Pauloa, Buby, El odioso se√±or, Don Sacramento y Don Rosario. La segunda por Fanny, las tres muchachas y El anciano militar. La tercera por Sagra y El cazador astuto. La cuarta por Madame Olga y El guapo muchacho. La quinta por todos y ‚ÄúEl rom√°ntico enamorado. La sexta por‚ÄùUnos‚Äù y ‚ÄúOtros‚Äù. Las dos √∫ltimas son comunidades de un solo personaje: El coro de viejos extra√±os y El explorador.",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "sombreros.html#temas-y-redes",
    "href": "sombreros.html#temas-y-redes",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "Temas y redes",
    "text": "Temas y redes\nUna vez analizada la conectividad de los personajes, a partir de ahora exploraremos dos m√©todos de modelado de t√≥picos. El primero, sin redes, se basa en el modelo LDA (Latent Dirichlet Allocation) para identificar los t√≥picos m√°s relevantes en el di√°logo de la obra. Consiste en agrupar palabras que aparecen juntas en el texto y que, por lo tanto, pueden ser consideradas como parte de un mismo tema. El segundo, a partir de redes, se basa en la extracci√≥n de t√≥picos a partir de la estructura de interacci√≥n entre los personajes. Como en el ejemplo de los personajes, se identifican comunidades de palabras que presentan una mayor densidad de interacciones entre s√≠ que con el resto de la red.\n\nModelado de t√≥picos sin redes\nEl LDA corresponde a una t√©cnica de aprendizaje no supervisado (sin la necesidad de una clasificaci√≥n previa por parte del investigador) que permite identificar los t√≥picos m√°s relevantes en un conjunto de documentos. A partir de la matriz de t√©rminos-documentos, el modelo asigna probabilidades a cada palabra de pertenecer a un t√≥pico. Se llama ‚Äúlatente‚Äù justamente porque trata de identificar temas que no est√°n expl√≠citos en el texto. La combinaci√≥n de palabras sirve de insumo para que el analista pueda inferir de qu√© trata el tema en concreto.\nEl c√≥digo abajo lleva a cabo un an√°lisis LDA para identificar los t√≥picos m√°s relevantes en los di√°logos de Tres sombreros de copa:\n\n\nC√≥digo\n# Carga los paquetes\nlibrary(quanteda)\nlibrary(topicmodels)\n\n# Extrae los tokens\ntk &lt;- tokens(tsc_d$dialogo, \n             remove_punct = TRUE, \n             remove_numbers = TRUE, \n             remove_symbols = TRUE)\n\ntk &lt;- tokens_tolower(tk)\n\ntk &lt;- tokens_remove(tk, \n                    c(stopwords(\"es\"),\n                      \"don\",\n                      \"usted\",\n                      \"hacer\",\n                      \"va\",\n                      \"voy\",\n                      \"si\"))\n\n# Crea la matriz de t√©rminos-documentos\ndtm &lt;- dfm(tk)\n\n# Convierte en el formato requerido\ndtm &lt;- convert(dtm, \n               to = \"topicmodels\") \n\n# Crea 20 t√≥picos\nld &lt;- LDA(dtm, k = 20)\n\n\n# Obtiene los 50 t√©rminos m√°s\n# importantes de cada t√≥pico\nd1 &lt;- terms(ld, 50)\n\n# Visualiza los resultados\nlibrary(reactable)\n\nreactable(d1, resizable=T, sortable = F)\n\n\n\n\n\n\nLa tabla presenta los palabras por orden de importancia en cada uno de los 20 t√≥picos generados autom√°ticamente. Se puede ver que muchas palabras se repitan en varios temas, a menudo con un peso distinto en cada uno de ellos. Por ejemplo, ‚Äúsombreros‚Äù y ‚ÄúDionisio‚Äù aparecen en los dos primeros t√≥picos, aunque en posiciones distintas.\nLa interpretaci√≥n de los resultados de un modelo LDA es un proceso iterativo y cualitativo. No hay una regla fija para determinar cu√°ntos t√≥picos son los m√°s adecuados. En este caso, hemos optado por 20 t√≥picos, pero el investigador puede ajustar este n√∫mero seg√∫n sus objetivos de investigaci√≥n. Adem√°s, dar nombre a cada uno de ellos no resulta f√°cil, pues, como hemos visto, las mismas palabras pueden repetirse, dificultando su asociaci√≥n con un tema concreto.\n\n\nExtracci√≥n de t√≥picos a partir de redes\nOtro modo de identificar los temas consiste en crear redes de palabras. En este caso, se considera que dos palabras est√°n conectadas si aparecen juntas en el texto. La red resultante permite identificar comunidades de palabras que presentan una mayor densidad de interacciones entre s√≠ que con el resto de la red. En el c√≥digo abajo, se extraen los t√≥picos a partir de la estructura de interacci√≥n entre las palabras:\n\n\nC√≥digo\n# Crea una base de datos\n# que ir√° acumular las coocurrencias\nres &lt;- data.frame()\n\n# Para cada di√°logo\nfor(i in 1:length(tk)){\n  \n  # Obtiene las palabras\n  ky &lt;- as.character(tk[[i]])\n  \n  # Si solo hay una palabra\n  # para al siguiente di√°logo\n  if(length(ky) &lt; 2){\n    next\n  }\n  \n  # Genera las coocurrencias\n  d1 &lt;- data.frame(from = ky[-length(ky)], to = ky[-1])\n  \n  # Establece el peso\n  d1$weight &lt;- 1\n  \n  # Acumula los resultados\n  res &lt;- rbind(res, d1)\n  \n}\n\n\n# res &lt;- res[! res$from%in%c(\"dionisio\",\"buby\",\"paula\"),]\n# \n# res &lt;- res[! res$to%in%c(\"dionisio\",\"buby\",\"paula\"),]\n\n# Simplifica la red para obtener\n# la frecuencia √∫nica de las coocurrencias\nlibrary(igraph)\n\n\ng &lt;- graph_from_data_frame(res, \n                           directed = FALSE)\n\ng &lt;- igraph::simplify(g, \n              remove.multiple = FALSE)\n\n\n# Crea una nueva base de datos\n# con la red simplificada\nrea &lt;- igraph::as_data_frame(g)\n\n# Agrega las coocurrencias por\n# diada de palabras\nag &lt;- aggregate(weight ~ from + to, \n                data = rea, \n                FUN = sum)\n\n\n# Elimina los casos en los que\n# solo hay una coocurrencia\nag &lt;- ag[ag$weight &gt; 1,]\n\n# convierte en un gr√°fico no direccional\ng &lt;- graph_from_data_frame(ag, \n                           directed = FALSE)\n\n# Establece la frecuencia como\n# el peso\nE(g)$weight &lt;- ag$weight\n\n\nHemos greado una red g no dirigida (que no considera el orden) a partir de las coocurrencias de palabras en los di√°logos. Contiene 595 pares de palabras √∫nicos que se han mencionado juntas en m√°s de una ocasi√≥n. A continuaci√≥n, calcularemos las centralidades betwenness y degree para identificar las palabras m√°s importantes en la red y permitir que filtremos los resultados para facilitar su visualizaci√≥n:\n\n\nC√≥digo\n# Calcula las centralidades de red\n# betweenness y degree\nbt &lt;- round(betweenness(g),3)\n\nd1 &lt;- data.frame(word=names(bt), \n                 betweenness=round(bt))\n\nbt &lt;- igraph::degree(g)\n\nd2 &lt;- data.frame(word=names(bt), \n                 degree=bt)\n\nd3 &lt;- merge(d2, d1, by=\"word\")\n\n\nd3 &lt;- d3[order(d3$betweenness, \n               decreasing = T),]\n\nlibrary(reactable)\n\nreactable(d3, resizable=T)\n\n\n\n\n\n\nEl paso siguiente consiste en crear comunidades de palabras seg√∫n su posici√≥n en la red. Para ello, eliminaremos las palabras con betweenness igual a cero. Luego, utilizaremos el algoritmo de Louvain, para identificar las comunidades existentes en la red. Finalmente, convertimos los resultados en una base de datos que nos posibilita identificar las palabras m√°s importantes en cada comunidad:\n\n\nC√≥digo\n# Para facilitar la visualizaci√≥n,\n# se eliminan las palabras con \n# un grado menor a 1 en la estad√≠stica\n# betweenness\n\nli &lt;- d3$word[d3$betweenness &lt; 1]\nga &lt;- g - li\n\n\n# Crea un cluster de palabras\n# seg√∫n la conectividad de red\nwc &lt;- cluster_louvain(ga)\n\n# Atribuye la membres√≠a a los \n# grupos\nV(ga)$membership &lt;- wc$membership\n\n\n# Fusiona los datos de membres√≠a\n# a cada cluster con los datos\n# de las palabras\nda &lt;- igraph::as_data_frame(ga, \n                            what = \"vertices\")\n\n\nnames(da)[1] &lt;- \"word\"\n\nd3 &lt;- merge(d3, da, by=\"word\")\n\n# Seleccion las 20 palabras\n# con m√°s peso en cada grupo\nlibrary(dplyr)\n\nzz &lt;- d3 |&gt; \n      arrange(desc(betweenness)) |&gt;\n      group_by(membership) |&gt;\n      slice(1:20) \n\n\nreactable(zz, resizable=T)\n\n\n\n\n\n\n\nFinalmente, visualizamos los resultados en una red de palabras. En ella, los nodos representan las palabras y los enlaces las coocurrencias entre ellas. Los colores de los nodos indican la comunidad a la que pertenecen, mientras que el tama√±o de los nodos refleja su importancia en la red:\n\n\nC√≥digo\n# Crea un gr√°fico de red\n# para los clusters\ncpo &lt;- igraph::components(ga)\nnclu &lt;- 5\nncomp &lt;- which(cpo$csize &gt; nclu)\nga &lt;- igraph::delete_vertices(ga, \n                              ! cpo$membership %in% ncomp)\n\n\nlibrary(networkD3)\n\ndd &lt;- igraph_to_networkD3(ga, \n                          group = V(ga)$membership)\n\nforceNetwork(Links = dd$links, \n             width = 600, \n             height = 800, \n             bounded = T,\n             linkDistance = 50, \n             charge=-20,\n             opacity=1,\n             opacityNoHover=0.3,\n             Nodes = dd$nodes, \n             Source = 'source', \n             Target = 'target', \n             NodeID = 'name', \n             Group = 'group',\n             fontSize = 20)\n\n\n\n\n\n\n\nAl analizar los resultados en la tabla y el gr√°fico, resulta m√°s sencillo identificar los temas a que pertenecen cada grupo de palabras. No solo eso, tambi√©n se evidencian las conexiones entre distintos temas. El primero tiene que ver con Dionisio y su habitaci√≥n. El segundo trata de objetos centrales como los sombreros de copa, las lucecitas en el puerto, los malabares o las farolas. Los clusters cinco y siete tratan, entre otras cosas, del di√°logo entre Paula y El odioso se√±or. El n√∫mero 8 trata del ni√±o que se ha ahogado y de la novia de Dionisio, llamada ‚Äúni√±a‚Äù por Don Sacramento, su padre.",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "sombreros.html#etiquetado-l√©xico",
    "href": "sombreros.html#etiquetado-l√©xico",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "Etiquetado l√©xico",
    "text": "Etiquetado l√©xico\nPodemos ir un paso m√°s all√° en la identificaci√≥n de t√≥picos con la ayuda del etiquetado de partes del discurso (POS Tagging, en su sigla en ingl√©s). Se trata de un proceso que consiste en asignar a cada palabra de un texto una etiqueta que indica su categor√≠a gramatical. Para ello, emplearemos el paquete udpipe y el modelo previamente entrenado en espa√±ol para identificar las palabras de cada di√°logo. Una vez etiquetadas, seleccionaremos solamente los sustantivos y adjetivos. Con esta informaci√≥n, tendremos m√°s insumos para enriquecer nuestra comprensi√≥n de los t√≥picos presentes en la obra.\nEl c√≥digo abajo lleva a cabo dicho proceso y nos ense√±a los resultados:\n\n\nC√≥digo\n# Crea una variable de identificaci√≥n\ntsc_d$id &lt;- 1:nrow(tsc_d)\n\n# Convierte en corpus el dataframe sin\n# los textos de introducci√≥n\ncs &lt;- corpus(tsc_d[tsc_d$personaje_A!=\"Introducci√≥n\",], \n             text_field = \"dialogo\",\n             docid_field = \"id\")\n\n# Abre el paquete udpipe para realizar \n# el etiquetado de los textos\nlibrary(udpipe)\n\n# Descarga el modelo previamente entrenado\n# (solo es necesario hacerlo una vez)\nm_es   &lt;- udpipe_download_model(language = \"spanish\")\n\n# Carga el modelo\nm_es &lt;- udpipe_load_model(m_es)\n\n# Genera las anotaciones y etiquetas\nd &lt;- udpipe_annotate(m_es, \n                     x=cs, \n                     doc_id = docnames(cs)) |&gt; \n  as.data.frame() |&gt; \n  dplyr::select(-sentence)\n\n\n# Selecciona solo los sustantivos y adjetivos\nd &lt;- d[d$upos%in%c(\"NOUN\",\"ADJ\"),]\n\n\n# A√±ade los personajes\nd &lt;- merge(d, \n           tsc_d[,c(\"id\",\"personaje_A\")], \n           by.x = \"doc_id\", \n           by.y=\"id\")\n\n\n# Filtra los campos deseados\nd &lt;- d[,c(\"personaje_A\",\"lemma\")]\n\n# Uniformiza y agrega las frecuencias\nd &lt;- d[tolower(d$lemma)!=\"dionisio\",]\nd$freq &lt;- 1\n\nag &lt;- aggregate(freq ~ personaje_A+lemma, \n                data = d, \n                FUN = sum)\n\n# Selecciona solamente los t√©rminos\n# que aparezcan m√°s de una vez\nag &lt;- ag[ag$freq&gt;1,]\n\n# Ordena por personaje y frecuencia\n# decreciente\nag &lt;- ag[order(ag$personaje_A, -ag$freq),]\n\n# Visualiza los resultados\nreactable(ag, resizable = T, sortable=T)",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "sombreros.html#an√°lisis-de-sentimiento",
    "href": "sombreros.html#an√°lisis-de-sentimiento",
    "title": "Tres sombreros de copaRedes en di√°logo",
    "section": "An√°lisis de sentimiento",
    "text": "An√°lisis de sentimiento\nEl an√°lisis de sentimiento ser√° la √∫ltima t√©cnica considerada en este curso. Se trata de un proceso que busca identificar y cuantificar la actitud expresada en un texto. Existen diversas maneras de llevar a cabo este an√°lisis, pero una de las m√°s comunes es la de emplear diccionarios de palabras previamente etiquetadas como positivas, negativas o neutras.\nEn el ejemplo abajo, hemos realizado la clasificaci√≥n manual de cada di√°logo como positivo, negativo o neutro. El paso siguiente ha sido emplear el paquete syuzhet para analizar los di√°logos de la obra y determinar su ‚Äúvalencia‚Äù. Finalmente, agregamos la informaci√≥n por personaje para saber su polaridad emocional. El c√≥digo abajo lleva a cabo dicho proceso y nos ense√±a los resultados:\n\n\nC√≥digo\n# Di√°logos positivos\npos &lt;- c(4,5,12,19,32,58,60,67,68,70,71,74,76,77,78,80,92,\n         98,111,172,229,230,235,236,260,264,269,306,309,\n         321,345,351,356,357,359,365,385,389,406,415,424,\n         428,432,436,438,447,448,449,464,472,474,482,485,\n         486,487,490,491,494,496,500,515,518,519,521,528,\n         533,538,577,617,621,627,629,648,653,716,741,757,\n         769,770,811,834)\n\n# Di√°logos negativos\nneg &lt;- c(7,17,22,47,49,53,61,63,64,72,96,108,112,113,120,\n         121,122,123,141,145,149,147,171,175,176,177,179,\n         181,185,187,188,190,203,204,205,220,254,258,259,\n         261,262,263,267,282,284,285,286,289,290,291,292,\n         311,312,314,322,326,334,370,375,376,396,405,418,\n         457,458,459,461,471,473,476,481,513,544,546,547,\n         549,551,552,553,555,567,575,584,585,587,588:596,\n         598,599,602,608,609,619,647,671,672,673,679,680,\n         681,683,684,685,687,688,693,697,715,725,737,751,\n         752,774,776,778,791,800,802,803,820,821,831,837)\n\n# Identifica las valencias\ntsc_d$valence &lt;- 0\ntsc_d$valence[pos] &lt;- 1\ntsc_d$valence[neg] &lt;- -1\n\n# Agrega la informaci√≥n por personaje\nag1 &lt;- aggregate(valence ~ personaje_A, \n                 data = tsc_d, \n                 FUN = sum)\n\n# Carga el paquete syuzhet\nlibrary(syuzhet)\n\n# Obtiene las emociones\nemo &lt;- get_nrc_sentiment(tsc_d$dialogo, \n                         language = \"spanish\")\nemo$negative &lt;- emo$negative * -1\n\n# Crea una variable de valencia neta\n# entre emociones positivas y negativas\nemo$emo &lt;- emo$positive + emo$negative\n\n# Estandariza la variable para \n# 1 positivo, 0 neutro y -1 negativo\nemo$emo2 &lt;- ifelse(emo$emo == 0, 0, \n                   ifelse(emo$emo &gt; 0, 1, \n                          -1))\n\n# Agrega la informaci√≥n por personaje\nemo$person &lt;- tsc_d$personaje_A\ntsc_d$emo &lt;- emo$emo2\nag2 &lt;- aggregate(emo ~ personaje_A,\n                 data = tsc_d, \n                 FUN = sum)\n\n# Fusiona las dos tablas para \n# comparar la valencia manual y\n# la autom√°tica por diccionario\nagg &lt;- merge(ag1, ag2, by=\"personaje_A\")\n\n# Nombre las variables para facilitar\n# la lectura\nnames(agg) &lt;- c(\"Personaje\", \n                \"Manual\",\n                \"Diccionario\")\n\n# Visualiza los resultados\nreactable(agg, \n          resizable = T, \n          sortable=T)\n\n\n\n\n\n\n\nComo vemos, los resultados no son muy animadores. La codificaci√≥n manual ha arrojado resultados muy distintos a la autom√°tica por medio de diccionario, especialmente para personajes centrales como Dionisio y Paula. En parte esto ocurre porque se trata de un texto humor√≠stico y sarc√°stico, lo que dificulta la clasificaci√≥n de los di√°logos en positivos o negativos. Pero una gran parte de la diferencia viene de la interpretaci√≥n de respuestas negativas -como ‚ÄúNo, no lo puedo.‚Äù, por ejemplo- como conteniendo carga negativa desde la perspectiva emocional o -‚Äú¬øY cu√°nto dinero llevaba usted en la cartera?‚Äù, como positiva.\nQuiz√°s la mejor manera de abordar este problema sea la de emplear un enfoque mixto, que combine la codificaci√≥n manual con la autom√°tica, por medio de un modelo de aprendizaje autom√°tico, para obtener una visi√≥n m√°s completa de la valencia emocional de los personajes.",
    "crumbs": [
      "Tres sombreros de copa"
    ]
  },
  {
    "objectID": "index.html#ejercicio-final",
    "href": "index.html#ejercicio-final",
    "title": "filoRAn√°lisis de textos literarios con R",
    "section": "Ejercicio final",
    "text": "Ejercicio final\nEl ejercicio final consistir√° en reproducir uno de los an√°lisis presentados durante el curso. Para ello, deb√©is instalar el R y el RStudio y los paquetes mencionados en la sesi√≥n Servicio t√©cnico y, a continuaci√≥n, copiar, pegar y ejecutar el c√≥digo contenido en las p√°ginas Preparaci√≥n y La Regenta.\nSe trata de la entrega de una captura de pantalla que demuestre la reproducci√≥n exitosa de alguno de los ejercicios propuestos en el apartado sobre ‚ÄúLa Regenta‚Äù. Cualquiera de ellos resulta v√°lido.\nLa fecha final para el env√≠o ser√° el 30/06/2025 v√≠a correo electr√≥nico a los profesores.",
    "crumbs": [
      "Introducci√≥n al curso"
    ]
  }
]